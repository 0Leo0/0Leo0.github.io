<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Lovelife</title>
  
  <subtitle>时光荏苒，岁月静好</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://0Leo0.github.io/"/>
  <updated>2018-11-27T04:39:22.830Z</updated>
  <id>https://0Leo0.github.io/</id>
  
  <author>
    <name>Leowen</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>case study_webcam face detection</title>
    <link href="https://0Leo0.github.io//2018/case_study_02.html"/>
    <id>https://0Leo0.github.io//2018/case_study_02.html</id>
    <published>2018-11-27T02:17:50.000Z</published>
    <updated>2018-11-27T04:39:22.830Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><a id="more"></a><h2 id="Webcam-face-detection"><a href="#Webcam-face-detection" class="headerlink" title="Webcam face detection"></a>Webcam face detection</h2><hr><pre><code>from preprocess import FaceDetectorfrom preprocess import imutils import argparseimport cv2 # construct the argument parse and parse the argumentsap = argparse.ArgumentParser()ap.add_argument(&quot;-f&quot;, &quot;--face&quot;, required = True,    help = &quot;path to where the face cascade resides&quot;)ap.add_argument(&quot;-v&quot;, &quot;--video&quot;,    help = &quot;path to the (optional) video file&quot;)args = vars(ap.parse_args())# construct the face detectorfd = FaceDetector(args[&quot;face&quot;])</code></pre><p>这里出现了一个新的包，<code>imutils</code>，这个包主要包含用于执行基本图像操作的便捷功能，例如调整大小。前面我们已经实现了<code>imutils</code>这个包了，如果没看的话，那么我们直接安装这个包也是可以的。执行<code>pip install imutils</code>就可以了，然后直接导入这个包即可(<code>import imutils</code>)。</p><p>我们同样需要一个haar级联分类器才能找到图像中的脸部。分类器被序列化为XML文件，可以由OpenCV加载。我们的face参数指向磁盘上的序列化XML级联分类器。</p><p>出于调试目的(或者系统没有网络摄像头)，我们创建了一个可选的命令行参数–video，它指向磁盘上的视频文件。为了防止无法使用网络摄像头，使用视频文件测试和调试他的实时系统仍然是一件好事。在这种情况下，我们只需要提供我们的视频文件目录给video参数即可。</p><p>最后我们通过传递cascade classifier的路径实例化我们的FaceDetector。</p><pre><code># if a video path was not supplied, grab the reference# to the grayif not args.get(&quot;video&quot;):    camera = cv2.VideoCapture(0)else:    camera = cv2.VideoCapture(args[&quot;video&quot;])</code></pre><p>如果我们未提供视频路径。在这种情况下，OpenCV将尝试从笔记本电脑的内置(或USB)网络摄像头读取视频。否则，OpenCV将打开video参数指向的视频文件。</p><p>在任何一种情况下，都使用<code>cv2.VideoCapture</code>函数。提供整数值0指示OpenCV从网络摄像头设备读取，而提供字符串表示OpenCV应打开路径指向的视频。提供无效路径将导致空指针，如果没有有效的视频文件，我们显然无法进行任何面部检测。</p><p>假设抓取对视频的引用成功，我们将此指针存储在camera变量中。</p><pre><code># keep loopingwhile True:    # grab the current frame    (grabbed,frame) = camera.read()    # if we are viewing a video and we did not grab a    # frame, then we have reached the end of the video    if args.get(&quot;video&quot;) and not grabbed:        break     # resize the frame and convert it to grayscale    frame = imutils.resize(frame,width=300)    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)</code></pre><p>下一步是开始循环视频中的所有帧 在最基本的层面上，视频只是放在一起的一系列图像，这意味着我们实际上可以一次读取这些帧。我们首先用while循环将保持循环遍历帧，直到满足以下两种情况之一：(1)视频已到达其结束且没有更多帧，或(2)用户过早地停止执行脚本。</p><p>在while循环里，我们首先通过调用相机的read()方法抓取视频中的下一帧。read方法返回两个值的元组：第一个是抓取的，用布尔值表示读取帧是否成功的true或false，第二个就是抓取的帧本身。</p><p>如果我们正在从文件中读取视频，但是并没有抓取到帧，则说明视频结束，这个时候应该用break退出循环。</p><p>否则，我们对帧进行一些预处理。首先就是调整帧的大小，使其宽度为300像素，以便更快地实时进行人脸检测。然后将帧转换为灰度。</p><pre><code>    # detect faces in the image and then clone the frame    # so that we can draw on it    faceRects = fd.detect(gray,scaleFactor=1.1,minNeighbors=5,        minSize=(30,30))    frameClone = frame.copy()    # loop over the face bounding boxes and draw them    for (fX,fY,fW,fH) in faceRects:        cv2.rectangle(frameClone,(fX,fY),(fX + fW,fY + fH),(0,255,0),2)    # show our detected faces    cv2.imshow(&quot;Face&quot;,frameClone)    # if the &apos;q&apos; key is pressed, stop the loop    if cv2.waitKey(1) &amp; 0xFF == ord(&quot;q&quot;):        break # cleanup the camera and close any open windows camera.release()cv2.destroyAllWindows() </code></pre><p>我们首先传递了灰度帧并应用了<code>FaceDetecto</code>r的<code>detect</code>方法。</p><p>但是为了在我们的图像上绘制一个边界框，我们决定首先创建一个框架的克隆，以防万一我们需要原始框架进行进一步的预处理。帧的克隆存储在frameClone中。</p><p>然后我们遍历图像中面部的边界框，并使用<code>cv2.rectangle</code>函数绘制它们。然后显示我们的结果。</p><p>当然，用户可能希望停止执行脚本。我们不用强制输入ctrl+c，而是检查用户是否在键盘上按了q键。</p><p>最后，我们release了对相机的引用，并且关闭了由OpenCV创建的任何打开的窗口。</p><p>执行脚本文件</p><p>提供video视频文件：</p><pre><code>python cam.py --face cascades\haarcascade_frontalface_default.xml --video video\myvideo.mp4</code></pre><p>不提供video文件</p><pre><code>python cam.py --face cascades\haarcascade_frontalface_default.xml</code></pre><p>执行结果：</p><p><img src="https://i.imgur.com/S3PoGOb.png" alt=""></p><p><img src="https://i.imgur.com/W9DSULB.png" alt=""></p><p>完整代码：</p><p>链接：<a href="https://pan.baidu.com/s/1MMrksgrEw5Xr-F2R6lDTpw" target="_blank" rel="noopener">https://pan.baidu.com/s/1MMrksgrEw5Xr-F2R6lDTpw</a>  提取码：lk0j </p><h3 id="更多的参考："><a href="#更多的参考：" class="headerlink" title="更多的参考："></a>更多的参考：</h3><p><a href="https://ppao.pyimagesearch.com/lessons/case-studies-webcam-face-detection/" target="_blank" rel="noopener">Case Studies – Webcam Face Detection</a></p><p><a href="http://www.pyimagesearch.com/2015/12/21/increasing-webcam-fps-with-python-and-opencv/" target="_blank" rel="noopener">Increasing webcam FPS with Python and OpenCV</a></p><p><a href="http://www.pyimagesearch.com/2015/12/28/increasing-raspberry-pi-fps-with-python-and-opencv/" target="_blank" rel="noopener">Increasing Raspberry Pi FPS with Python and OpenCV</a></p><p><a href="http://www.pyimagesearch.com/2016/01/04/unifying-picamera-and-cv2-videocapture-into-a-single-class-with-opencv/" target="_blank" rel="noopener">Unifying picamera and cv2.VideoCapture into a single class with OpenCV</a></p><p><a href="https://www.pyimagesearch.com/2016/01/18/multiple-cameras-with-the-raspberry-pi-and-opencv/" target="_blank" rel="noopener">Multiple cameras with the Raspberry Pi and OpenCV</a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="计算机视觉" scheme="https://0Leo0.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="case study" scheme="https://0Leo0.github.io/tags/case-study/"/>
    
  </entry>
  
  <entry>
    <title>case study_face detection</title>
    <link href="https://0Leo0.github.io//2018/case_study_01.html"/>
    <id>https://0Leo0.github.io//2018/case_study_01.html</id>
    <published>2018-11-26T14:17:50.000Z</published>
    <updated>2018-11-26T13:11:11.813Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><a id="more"></a><h2 id="Face-Detection"><a href="#Face-Detection" class="headerlink" title="Face Detection"></a>Face Detection</h2><hr><pre><code>from __future__ import print_functionfrom preprocess import FaceDetectorimport argparseimport cv2 ap = argparse.ArgumentParser()ap.add_argument(&quot;-f&quot;, &quot;--face&quot;, required = True,    help = &quot;path to where the face cascade resides&quot;)ap.add_argument(&quot;-i&quot;, &quot;--image&quot;, required = True,    help = &quot;path to where the image file resides&quot;)args = vars(ap.parse_args())# load the image and convert it to grayscaleimage = cv2.imread(args[&quot;image&quot;])gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)</code></pre><p>首先导入必要的包，为了保持代码的整洁，在同目录下新建了一个preprocess文件夹，然后新建一个<strong>init</strong>.py文件，使得python解释器将该文件夹解释为包。在该文件夹下还有个facedetector.py文件。不懂<strong>init</strong>.py的参考前面的文章。然后我们解析参数，读取图片并将图片转化为灰度图像。</p><p><img src="https://i.imgur.com/XEGM66O.png" alt=""></p><p>但是，让我们不要走得太远。在我们考虑在图像中寻找面部之前，我们首先需要定义一个类来处理我们如何在图像中找到面部。</p><p>新建一个facedetector.py文件(该文件就是上面导入的包)</p><pre><code>import cv2 class FaceDetector:    def __init__(self,faceCascadepath):        # load the face detector         self.faceCascade = cv2.CascadeClassifier(faceCascadepath)    def detect(self,image,scaleFactor = 1.1,minNeighbors=5,minSize=(30,30)):        # detect faces in the image         rects = self.faceCascade.detectMultiScale(image,            scaleFactor=scaleFactor,minNeighbors=minNeighbors,            minSize=minSize,flags=cv2.CASCADE_SCALE_IMAGE)        # return the rectangles representing bounding        # boxes around the faces         return rects </code></pre><p>为了构建人脸识别软件，我们采用在OpenCV中内置的Haar级联分类器。这些分类器已经过预先训练以识别面孔！</p><p>构建我们自己的分类器当然不在本案例研究的范围之内。但如果我们想，我们需要很多“积极”和“消极”的图像。正图像将包含具有面部的图像，而负面图像将包含没有面部的图像。基于此数据集，我们可以提取特征来表征图像中的面部(或没有面部)并构建我们自己的分类器。这将是很多工作，而且非常耗时。</p><p>无论如何，这些分类器通过以不同的比例尺寸从左到右，从上到下扫描图像来工作。从左到右，从上到下扫描图像称为“滑动窗口(sliding window)”方法。</p><p>当窗口从左向右和从上到下移动时，一次一个像素，根据我们提供给分类器的参数，询问分类器是否“认为”在当前窗口中存在面部。</p><p>在类里面，我们定义了构造函数，该函数需要一个参数——我们级联分类器所在的路径。此分类器被序列化为XML文件。对<code>cv2.CascadeClassifier</code>的调用将对分类器进行反序列化，将其加载到内存中，并允许我们检测图像中的面部。</p><p>为了在图像中实际找到面部，我们接着定义了检测方法。该函数需要一个必需参数，即想要找到面部的图像，后跟三个可选参数。让我们来看看这些参数意味着什么：</p><p><strong>scaleFactor</strong>:图像大小在每个图像尺度上减少了多少。这个值用于创建缩放金字塔，以便检测图像中多个缩放的面部(一些面可能更接近前景，因此更大；其他面可能更小并且在背景中，因此使用不同的缩放)。比如设置值为1.05，则表明我们在金字塔中的每个级别将图像的大小减小了5％。</p><p><strong>minNeighbors</strong>:每个窗口应该有多少个neighbors才能将窗口中的区域视为一个脸。级联分类器将检测面部周围的多个窗口。此参数控制需要检测多少矩形(Neighbors)才能将窗口标记为面部。</p><p><strong>minSize</strong>:宽度和高度(以像素为单位)的元组，表示窗口的最小尺寸。小于此大小的边界框将被忽略。从(30,30)开始并从那里进行微调是一个好主意。</p><p>通过调用在FaceDetector类的构造函数中创建的分类器的<code>detectMultiScale</code>方法，处理检测图像中的实际面部。我们使用我们默认的<code>scaleFactor</code>，<code>minNeighbors</code>和<code>minSize</code>，然后该方法为我们完成了整个人脸检测过程！</p><p>然后，<code>detectMultiScale</code>方法返回<code>rects</code>，这是一个包含图像中面部边界框的元组列表。这些边界框只是面部的(x，y)位置，以及框的宽度和高度。</p><p>接着，让我们继续<code>detect_faces.py</code>文件的编写，来实现我们自己的图像面部识别。</p><p>文件detect_faces.py</p><pre><code># find faces in the imagefd = FaceDetector(args[&quot;face&quot;])faceRects = fd.detect(gray,scaleFactor=1.1,minNeighbors=5,    minSize=(30,30))print(&quot;I found {} face(s)&quot;.format(len(faceRects)))    # loop over the faces and draw a rectangle around eachfor (x,y,w,h) in faceRects:    cv2.rectangle(image,(x,y),(x + w,y + h),(0,255,0),2)# show the detected facescv2.imshow(&quot;Faces&quot;,image)cv2.waitKey(0)</code></pre><p>我们首先实例化我们的FaceDetector类，提供XML分类器的路径作为唯一参数。通过调用detect方法检测传入图像中的实际面部。然后打印我们在图像中一共找到了几个faces。</p><p>但是为了在图像周围实际绘制一个边界框，我们需要单独循环它们。同样，每个边界框只是一个有四个值的元组：在图像中，x和y为起始位置，然后是脸部的宽度和高度。</p><p>对<code>cv2.rectangle</code>的调用会在face上绘制一个绿色框。最后执行我们的脚本。</p><p>文件目录</p><p><img src="https://i.imgur.com/qrQAY67.png" alt=""></p><p>执行脚本文件</p><pre><code>F:\20181116\Case Studies, 3nd Edition\face detect&gt;python detect_faces.py --image &quot;My Snapshot.jpg&quot; --face cascades\haarcascade_frontalface_default.xmlI found 1 face(s)</code></pre><p>显示结果：</p><p><img src="https://i.imgur.com/kFaZ7D8.jpg" alt=""></p><p>需要注意的是，图片最好不要有中文路径，不然报错</p><pre><code>F:\20181116\Case Studies, 3nd Edition\face detect&gt;python detect_faces.py -image GDP组合.jpg --face cascades\haarcascade_frontalface_default.xml lusage: detect_faces.py [-h] -f FACE -i IMAGEdetect_faces.py: error: unrecognized arguments: GDP组合.jpg</code></pre><p>也许这看上去好像很完美了，但是当我们多测试几张图片的时候，发现了如下的结果</p><p><img src="https://i.imgur.com/LqsLqYJ.png" alt=""></p><pre><code>F:\20181116\Case Studies, 3nd Edition\face detect&gt;python detect_faces.py --i spurs.jpg --face cascades\haarcascade_frontalface_default.xmlI found 3 face(s)</code></pre><p>明明没有Tim的脸，为啥检测到了三个脸呢？</p><p>答案在于我们上面讨论过的<code>cv2.detectMutliScale</code>函数的参数。这些参数往往是敏感的，一组图像的某些参数选择不适用于另一组图像。</p><p>在大多数情况下，罪魁祸首将是<code>scaleFactor</code>参数。在其他情况下，它可能是<code>minNeighbors</code>。但作为调试规则，从<code>scaleFactor</code>开始，根据需要进行调整，然后转到<code>minNeighbors</code>。</p><p>考虑到这个调试规则，我们首先改变了对FaceDetector检测方法的调用：</p><pre><code>faceRects = fd.detect(gray,scaleFactor=1.3,minNeighbors=5,    minSize=(30,30))</code></pre><p>唯一的变化是<code>scaleFactor</code>参数，将其从1.1更改为1.3。</p><p>我们在看一次结果：</p><p><img src="https://i.imgur.com/ZGllO8b.png" alt=""></p><p>很显然，这一次结果是正确的，只有两个面部(虽然石佛和妖刀退役了，跑车也远离了圣城)，但无论如何我们的结果是正确的。</p><p>完整代码：</p><p>链接：<a href="https://pan.baidu.com/s/16rPsfhpV8pbSd-fKvAJ07w" target="_blank" rel="noopener">https://pan.baidu.com/s/16rPsfhpV8pbSd-fKvAJ07w</a> 密码：d4c9</p><h3 id="更多的参考："><a href="#更多的参考：" class="headerlink" title="更多的参考："></a>更多的参考：</h3><p><a href="https://ppao.pyimagesearch.com/lessons/case-studies-face-detection/" target="_blank" rel="noopener">Case Studies – Face Detection</a></p><p><a href="https://ppao.pyimagesearch.com/wp-content/uploads/2016/08/viola2001.pdf" target="_blank" rel="noopener">Rapid Object Detection using a Boosted Cascade of Simple Features</a></p><p><a href="http://www.pyimagesearch.com/2014/11/10/histogram-oriented-gradients-object-detection/" target="_blank" rel="noopener">HOG + Linear SVM framework,</a></p><p><a href="http://www.pyimagesearch.com/2015/03/16/image-pyramids-with-python-and-opencv/" target="_blank" rel="noopener">image pyramid</a></p><p><a href="http://www.pyimagesearch.com/2015/03/23/sliding-windows-for-object-detection-with-python-and-opencv/" target="_blank" rel="noopener">sliding windows</a></p><p><a href="https://github.com/opencv/opencv/tree/master/data/haarcascades" target="_blank" rel="noopener">haarcascades</a></p><p><a href="http://www.pyimagesearch.com/2015/11/09/pedestrian-detection-opencv/" target="_blank" rel="noopener">pre-trained HOG detector to detect pedestrians in images</a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="计算机视觉" scheme="https://0Leo0.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="case study" scheme="https://0Leo0.github.io/tags/case-study/"/>
    
  </entry>
  
  <entry>
    <title>OpenCV_python3_14</title>
    <link href="https://0Leo0.github.io//2018/OpenCV_python3_14.html"/>
    <id>https://0Leo0.github.io//2018/OpenCV_python3_14.html</id>
    <published>2018-11-24T16:17:50.000Z</published>
    <updated>2018-11-26T09:21:04.081Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><a id="more"></a><h2 id="Practical-Python-and-OpenCV-3rd-Edition-14"><a href="#Practical-Python-and-OpenCV-3rd-Edition-14" class="headerlink" title="Practical Python and OpenCV,3rd Edition 14"></a>Practical Python and OpenCV,3rd Edition 14</h2><hr><h3 id="Contours"><a href="#Contours" class="headerlink" title="Contours"></a>Contours</h3><p>OpenCV提供了在图像中查找“曲线”的方法，称为轮廓。轮廓是点的曲线，曲线中没有间隙。轮廓对形状近似和分析等方面非常有用。</p><p>为了在图像中找到轮廓，您需要首先使用边缘检测方法或阈值处理来获得图像的二值化。在下面的例子中，我们将使用Canny边缘检测器找到硬币的轮廓，然后找到硬币的实际轮廓。</p><p>新建一个counting_coins.py文件</p><pre><code>from __future__ import print_functionimport numpy as npimport argparseimport cv2# Construct the argument parser and parse the argumentsap = argparse.ArgumentParser()ap.add_argument(&quot;-i&quot;, &quot;--image&quot;, required = True,    help = &quot;Path to the image&quot;)args = vars(ap.parse_args())# Load the image, convert it to grayscale, and blur it slightlyimage = cv2.imread(args[&quot;image&quot;])gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)blurred = cv2.GaussianBlur(gray, (11, 11), 0)cv2.imshow(&quot;Image&quot;, image)# The first thing we are going to do is apply edge detection to# the image to reveal the outlines of the coinsedged = cv2.Canny(blurred, 30, 150)cv2.imshow(&quot;Edges&quot;, edged)</code></pre><p>正如前一章讨论的边缘检测方法一样，我们将把图像转换为灰度，然后应用高斯模糊，使边缘检测器更容易找到硬币的轮廓。我们这次使用了更大的模糊大小，σ=11.</p><p>然后，我们通过应用Canny边缘检测器来获得边缘图像。再次，正如在先前的边缘检测示例中，任何低于30的梯度值被认为是非边缘，而高于150的任何值被认为是确定的边缘。</p><p><img src="https://i.imgur.com/lKqqUTg.png" alt=""></p><pre><code># Find contours in the edged image.# NOTE: The cv2.findContours method is DESTRUCTIVE to the image# you pass in. If you intend on reusing your edged image, be# sure to copy it before calling cv2.findContours(_,cnts,_) = cv2.findContours(edged.copy(),cv2.RETR_EXTERNAL,        cv2.CHAIN_APPROX_SIMPLE)# How many contours did we find?print(&quot;I count {} coins in this image&quot;.format(len(cnts)))# Let&apos;s highlight the coins in the original image by drawing a# green circle around themcoins = image.copy()cv2.drawContours(coins,cnts,-1,(0,255,0),2)cv2.imshow(&quot;Coins&quot;,coins)cv2.waitKey(0)</code></pre><p><img src="https://i.imgur.com/I0Jr76C.png" alt=""></p><p>现在我们有了硬币的轮廓，我们可以找到the contours of the outlines。我们使用<code>cv2.findContours</code>函数来实现。此方法返回一个3元组：(1)应用轮廓检测后的图像(经过修改并基本上被破坏)，(2)轮廓本身，cnts以及(3)轮廓的层次结构(见下文)。</p><p><strong><font color="red">Note:</font></strong></p><p>The return tuple of cv2. findContours has changed in OpenCV 3.0. Originally in OpenCV 2.4.X, this tuple was only a 2-tuple, consisting of just the contours themselves and the associated hierarchy. However, in OpenCV 3.0, we have a third value added to the return tuple: the image itself after applying the contour detection algorithm. This is a small, minor change (and one that I’m personally not crazy about since it breaks backwards compatibility with so many scripts), but something that can definitely trip you up when working with both OpenCV 2.4.X and OpenCV 3.0. Be sure to take special care when using the cv2. findContours function if you intend for your code to be cross-version portable.</p><p><code>cv2.findContours</code>的第一个参数是我们的边缘图像。重要的是要注意，此函数对您传入的图像具有破坏性。如果您打算稍后在代码中使用该图像，最好使用NumPy复制方法复制它。</p><p>第二个参数是我们想要的轮廓类型。我们使用<code>cv2.RETR_EXTERNAL</code>来仅检索最外面的轮廓(即，跟随硬币轮廓的轮廓)。我们也可以通过<code>cv2.RETR_LIST</code>来获取所有轮廓。其他方法包括使用<code>cv2.RETR_COMP</code>和<code>cv2.RETR_TREE</code>的层次轮廓，但层次结构轮廓不在本文的范围。</p><p>我们的最后一个参数是我们想要近似轮廓。我们使用<code>cv2.CHAIN_APPROX_SIMPLE</code>仅将水平，垂直和对角线段压缩到其端点。 这节省了计算和内存。如果我们想要轮廓上的所有点，没有压缩，我们可以传入<code>cv2.CHAIN_APPROX_NONE</code>; 但是，使用此功能时要非常谨慎。 沿轮廓检索所有点通常是不必要的并且浪费资源。</p><p>我们的轮廓cnts只是一个Python列表。我们可以使用它上面的len函数来计算返回的轮廓数。</p><p>当我们执行我们的脚本时，我们将输出“我在此图像中计算9个硬币”打印到我们的控制台</p><pre><code>F:\20181116\Practical Python and OpenCV, 3rd Edition&gt;python counting_coins.py -i coins.pngI count 9 coins in this image</code></pre><p>现在，我们可以绘制轮廓。为了不在我们的原始图像上绘制，我们制作原始图像的副本，赋值给coins。</p><p>对<code>cv2.drawContours</code>的调用会在我们的图像上绘制实际轮廓。 函数的第一个参数是我们想要绘制的图像。第二个是我们的轮廓列表。 接下来，我们有轮廓指数。通过指定负值-1，我们指示我们要绘制所有轮廓。但是，我们也会提供一个索引i，这将是cnts中的第i个轮廓。这将允许我们只绘制一个轮廓而不是所有轮廓。</p><p>例如，以下是分别绘制第一，第二和第三轮廓的一些代码：</p><pre><code>cv2.drawContours(coins, cnts, 0, (0, 255, 0), 2)cv2.drawContours(coins, cnts, 1, (0, 255, 0), 2)cv2.drawContours(coins, cnts, 2, (0, 255, 0), 2)</code></pre><p><code>cv2.drawContours</code>函数的第四个参数是我们要绘制的线的颜色。在这里，我们使用绿色。</p><p>最后，我们的最后一个参数是我们绘制的线的粗细。我们将绘制厚度为两个像素的轮廓。</p><p>让我们从图像中裁剪每个硬币：</p><pre><code># Now, let&apos;s loop over each contourfor (i,c) in enumerate(cnts):    # We can compute the &apos;bounding box&apos; for each contour, which is    # the rectangle that encloses the contour    (x,y,w,h) = cv2.boundingRect(c)    # Now that we have the contour, let&apos;s extract it using array    # slices    print(&quot;Coin #{}&quot;.format(i+1))    coin = image[y:y + h,x:x + w]    cv2.imshow(&quot;Coin&quot;,coin)    # Just for fun, let&apos;s construct a mask for the coin by finding    # The minumum enclosing circle of the contour    mask = np.zeros(image.shape[:2],dtype=&quot;uint8&quot;)    ((centerX,centerY),radius) = cv2.minEnclosingCircle(c)    cv2.circle(mask,(int(centerX),int(centerY)),int(radius),255,-1)    mask = mask[y:y + h,x:x + w]    cv2.imshow(&quot;Masked Coin&quot;,cv2.bitwise_and(coin,coin,mask=mask))    cv2.waitKey(0)</code></pre><p>然后，我们在当前轮廓上使用<code>cv2.boundingRect</code>函数。此方法找到我们的轮廓适合的“封闭框”，允许我们从图像中裁剪它。该函数采用单个参数，一个轮廓，然后返回矩形开始的x和y位置的元组，后跟矩形的宽度和高度。</p><p>然后我们使用我们的边界框坐标和NumPy阵列切片从图像中裁剪硬币。</p><p>如果我们能找到轮廓的边界框，为什么不在轮廓上加一个圆？毕竟，硬币是圆圈。</p><p>我们首先将mask初始化为NumPy零数组，其原始图像的宽度和高度相同。</p><p>我们调用<code>cv2.minEnclosingCircle</code>方法来fit我们轮廓的圆。 我们传入一个圆形变量，即当前轮廓，并给出圆的x和y坐标及其半径。</p><p>使用(x，y)坐标和半径，我们可以在我们的mask上画一个圆圈，代表硬币。</p><p>然后我们将与裁剪硬币完全相同的方式裁剪mask。</p><p>为了仅显示硬币的前景并忽略背景，我们使用硬币图像和硬币的mask来调用我们可靠的按位AND函数。</p><p><img src="https://i.imgur.com/GxEvY9D.png" alt=""></p><p><strong>用到的函数</strong></p><p><span id="inline-blue">cv2.findContours</span></p><p><span id="inline-blue">np.uint8</span></p><p><span id="inline-blue">cv2.drawContours</span></p><p><span id="inline-blue">cv2.Canny</span></p><h3 id="更多的参考："><a href="#更多的参考：" class="headerlink" title="更多的参考："></a>更多的参考：</h3><p><a href="https://ppao.pyimagesearch.com/lessons/ppao-chapter-11-contours/" target="_blank" rel="noopener">PPaO Chapter 11 – Contours</a></p><p><a href="https://www.pyimagesearch.com/2015/05/04/target-acquired-finding-targets-in-drone-and-quadcopter-video-streams-using-python-and-opencv/" target="_blank" rel="noopener">Target acquired: Finding targets in drone and quadcopter video streams using Python and OpenCV</a></p><p><a href="https://www.pyimagesearch.com/2016/03/28/measuring-size-of-objects-in-an-image-with-opencv/" target="_blank" rel="noopener">Measuring size of objects in an image with OpenCV</a></p><p><a href="https://www.pyimagesearch.com/2016/02/08/opencv-shape-detection/" target="_blank" rel="noopener">OpenCV shape detection</a></p><p><a href="http://www.pyimagesearch.com/2015/11/30/detecting-machine-readable-zones-in-passport-images/" target="_blank" rel="noopener">Detecting machine-readable zones in passport images</a></p><p><a href="http://www.pyimagesearch.com/2014/11/24/detecting-barcodes-images-python-opencv/" target="_blank" rel="noopener">Detecting Barcodes in Images with Python and OpenCV</a></p><p><a href="http://www.pyimagesearch.com/2014/09/01/build-kick-ass-mobile-document-scanner-just-5-minutes/" target="_blank" rel="noopener">How to Build a Kick-Ass Mobile Document Scanner in Just 5 Minutes</a></p><hr>]]></content>
    
    <summary type="html">
    
      第十四个代码
    
    </summary>
    
      <category term="计算机视觉" scheme="https://0Leo0.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="Opencv" scheme="https://0Leo0.github.io/tags/Opencv/"/>
    
  </entry>
  
  <entry>
    <title>case study 3rd——说在前面的话</title>
    <link href="https://0Leo0.github.io//2018/case_study_00.html"/>
    <id>https://0Leo0.github.io//2018/case_study_00.html</id>
    <published>2018-11-24T14:17:50.000Z</published>
    <updated>2018-11-26T09:36:03.491Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><a id="more"></a><h2 id="case-study-00"><a href="#case-study-00" class="headerlink" title="case study 00"></a>case study 00</h2><hr><p>获取额外的补充材料，请在下面的网址中注册获取</p><p><a href="https://ppao.pyimagesearch.com/" target="_blank" rel="noopener">补充材料</a></p><p>关于字体：</p><p><em>Italic</em>:</p><p>表示您应注意的关键术语和重要信息。 也可以基于内涵表示数学方程或公式。</p><p><em>**Bold</em>:</p><p>你应该注意的重要信息。</p><p><strong>用到的函数</strong></p><p><span id="inline-blue">cv2.findContours</span></p><p><span id="inline-blue">np.uint8</span></p><p><span id="inline-blue">cv2.drawContours</span></p><p><span id="inline-blue">cv2.Canny</span></p><h3 id="更多的参考："><a href="#更多的参考：" class="headerlink" title="更多的参考："></a>更多的参考：</h3><p><a href="https://ppao.pyimagesearch.com/lessons/ppao-chapter-11-contours/" target="_blank" rel="noopener">PPaO Chapter 11 – Contours</a></p><p><a href="https://www.pyimagesearch.com/2015/05/04/target-acquired-finding-targets-in-drone-and-quadcopter-video-streams-using-python-and-opencv/" target="_blank" rel="noopener">Target acquired: Finding targets in drone and quadcopter video streams using Python and OpenCV</a></p><p><a href="https://www.pyimagesearch.com/2016/03/28/measuring-size-of-objects-in-an-image-with-opencv/" target="_blank" rel="noopener">Measuring size of objects in an image with OpenCV</a></p><p><a href="https://www.pyimagesearch.com/2016/02/08/opencv-shape-detection/" target="_blank" rel="noopener">OpenCV shape detection</a></p><p><a href="http://www.pyimagesearch.com/2015/11/30/detecting-machine-readable-zones-in-passport-images/" target="_blank" rel="noopener">Detecting machine-readable zones in passport images</a></p><p><a href="http://www.pyimagesearch.com/2014/11/24/detecting-barcodes-images-python-opencv/" target="_blank" rel="noopener">Detecting Barcodes in Images with Python and OpenCV</a></p><p><a href="http://www.pyimagesearch.com/2014/09/01/build-kick-ass-mobile-document-scanner-just-5-minutes/" target="_blank" rel="noopener">How to Build a Kick-Ass Mobile Document Scanner in Just 5 Minutes</a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="计算机视觉" scheme="https://0Leo0.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="case study" scheme="https://0Leo0.github.io/tags/case-study/"/>
    
  </entry>
  
  <entry>
    <title>OpenCV_python3_13</title>
    <link href="https://0Leo0.github.io//2018/OpenCV_python3_13.html"/>
    <id>https://0Leo0.github.io//2018/OpenCV_python3_13.html</id>
    <published>2018-11-23T16:17:50.000Z</published>
    <updated>2018-11-26T07:18:57.257Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><a id="more"></a><h2 id="Practical-Python-and-OpenCV-3rd-Edition-13"><a href="#Practical-Python-and-OpenCV-3rd-Edition-13" class="headerlink" title="Practical Python and OpenCV,3rd Edition 13"></a>Practical Python and OpenCV,3rd Edition 13</h2><hr><h3 id="Gradients-and-Edge-detection"><a href="#Gradients-and-Edge-detection" class="headerlink" title="Gradients and Edge detection"></a>Gradients and Edge detection</h3><p>本章主要涉及渐变和边缘检测。形式上，边缘检测体现了数学方法，以在图像中找到像素强度的亮度明显变化的点。</p><p>我们要做的第一件事是找到灰度图像的“渐变”，允许我们在x和y方向找到类似边缘的区域。</p><p>然后，我们将应用Canny边缘检测，多级降噪（模糊）过程，找到图像的梯度（利用水平和垂直方向上的Sobel核）、非最大抑制和滞后阈值。听起来似乎很难懂。这并不妨碍我们继续前进。但是，如果您对梯度和边缘检测背后的数学感兴趣，我鼓励您阅读算法。总的来说，它们并不复杂，并且可以深入了解OpenCV的幕后操作。</p><h4 id="laplacian-and-sobel"><a href="#laplacian-and-sobel" class="headerlink" title="laplacian and sobel"></a>laplacian and sobel</h4><pre><code>import numpy as np import argparseimport cv2 ap = argparse.ArgumentParser()ap.add_argument(&apos;-i&apos;,&quot;--image&quot;,required=True,    help=&quot;path to the image&quot;)args = vars(ap.parse_args())image = cv2.imread(args[&quot;image&quot;])image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)cv2.imshow(&quot;orginal&quot;,image)# Compute the Laplacian of the imagelap = cv2.Laplacian(image,cv2.CV_64F)lap = np.uint8(np.absolute(lap))cv2.imshow(&quot;Laplacian&quot;,lap)cv2.waitKey(0)</code></pre><p>当计算梯度和边缘时，我们（通常）在单个通道上计算它们——在这种情况下，我们使用灰度图像；然而，我们也可以为RGB图像的每个通道计算梯度。为了简单起见，让我们继续使用灰度图像，因为这是大多数情况下将使用的。</p><p>我们使用拉普拉斯算法通过调用<code>cv2.Laplacian</code>函数来计算梯度幅度图像。第一个参数是我们的灰度图像——我们想要计算梯度幅度表示的图像。第二个参数是输出图像的数据类型。</p><p>前面，我们主要使用8位无符号整数。为什么我们现在使用64位浮点数？</p><p>原因涉及图像中黑色到白色和白色到黑色的转换。</p><p>从黑色到白色的转变被认为是正斜率，而从白色到黑色的转变是负斜率。如果您还记得前面我们对图像算术的讨论，您就会知道8位无符号整数不代表负值。如果使用OpenCV，它将被剪裁为零，或者将使用NumPy执行模数运算。</p><p>这里简短的回答是，如果在计算梯度幅度图像时不使用浮点数据类型，则会丢失边缘，特别是白色到黑色的过渡。</p><p>为了确保捕获所有边，使用浮点数据类型，然后获取渐变图像的绝对值并将其转换回8位无符号整数。这绝对是一项重要的技术需要注意——否则你会丢失图像中的边缘！</p><p><img src="https://i.imgur.com/892FCpH.png" alt=""></p><p>让我们继续计算Sobel梯度表示</p><pre><code># Compute gradients along the X and Y axis, respectivelysobelX = cv2.Sobel(image,cv2.CV_64F,1,0)sobelY = cv2.Sobel(image,cv2.CV_64F,0,1)# The sobelX and sobelY images are now of the floating# point data type -- we need to take care when converting# back to an 8-bit unsigned integer that we do not miss# any images due to clipping values outside the range# of [0, 255]. First, we take the absolute value of the# graident magnitude images, THEN we convert them back# to 8-bit unsigned integerssobelX = np.uint8(np.absolute(sobelX))sobelY = np.uint8(np.absolute(sobelY))# We can combine our Sobel gradient images using our# bitwise ORsobelCombined = cv2.bitwise_or(sobelX,sobelY)# Show our Sobel imagescv2.imshow(&quot;Sobel X&quot;,sobelX)cv2.imshow(&quot;Sobel Y&quot;,sobelY)cv2.imshow(&quot;Sobel Combined&quot;,sobelCombined)cv2.waitKey(0)</code></pre><p>使用Sobel算子，我们可以计算沿x和y轴的梯度幅度表示，使我们能够找到水平和垂直边缘区域。</p><p>Sobel算子的第一个参数是我们想要计算梯度表示的图像。然后，就像上面的拉普拉斯算例一样，我们使用浮点数据类型。最后两个参数分别是x和y方向上导数的顺序。指定值1和0(y方向上的导数为0，平行于y轴？)以查找垂直边缘状区域，指定0和1以查找水平边缘状区域。</p><p>我们确保通过获取浮点图像的绝对值然后将其转换为8位无符号整数来找到所有边。</p><p>为了在x和y方向上组合梯度图像，我们可以应用按位OR。请记住，当任一像素大于零时，OR运算为真。因此，如果存在水平或垂直边缘，则给定像素将为True。</p><p><img src="https://i.imgur.com/nYhBPi1.png" alt=""></p><p>左上角：原始硬币图像。右上：沿x轴计算Sobel梯度大小（找到垂直边缘）。左下：沿y轴计算Sobel梯度（找到水平边缘）。右下：应用按位OR来组合两个Sobel表示。</p><h4 id="canny-edge-detector"><a href="#canny-edge-detector" class="headerlink" title="canny edge detector"></a>canny edge detector</h4><p>Canny边缘检测器是一个多步骤的过程。它涉及模糊图像以消除噪声，计算x和y方向上的Sobel梯度图像，抑制边缘，以及最后确定像素是否是“边缘样”的滞后阈值阶段。</p><p>新建一个canny.py文件</p><pre><code>import numpy as npimport argparseimport cv2# Construct the argument parser and parse the argumentsap = argparse.ArgumentParser()ap.add_argument(&quot;-i&quot;, &quot;--image&quot;, required = True,    help = &quot;Path to the image&quot;)args = vars(ap.parse_args())# Load the image, convert it to grayscale, and blur it# slightly to remove high frequency edges that we aren&apos;t# interested inimage = cv2.imread(args[&quot;image&quot;])image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)image = cv2.GaussianBlur(image, (5, 5), 0)cv2.imshow(&quot;Blurred&quot;, image)# When performing Canny edge detection we need two values# for hysteresis: threshold1 and threshold2. Any gradient# value larger than threshold2 are considered to be an# edge. Any value below threshold1 are considered not to# ben an edge. Values in between threshold1 and threshold2# are either classified as edges or non-edges based on how# the intensities are &quot;connected&quot;. In this case, any gradient# values below 30 are considered non-edges whereas any value# above 150 are considered edges.canny = cv2.Canny(image, 30, 150)cv2.imshow(&quot;Canny&quot;, canny)cv2.waitKey(0)</code></pre><p>我们要做的第一件事是导入我们的包并解析我们的参数。然后我们加载图像，将其转换为灰度，并使用高斯模糊方法对其进行模糊处理。通过在边缘检测之前应用模糊，我们将帮助消除图像中我们不感兴趣的“嘈杂”边缘。我们这里的目标是只找到硬币的轮廓。</p><p>应用Canny边缘检测器通过使用<code>cv2.Canny</code>函数执行。我们提供的第一个参数是模糊的灰度图像。然后，我们需要提供两个值：<code>threshold1</code>和<code>threshold2</code>。</p><p>任何大于<code>threshold2</code>的梯度值都被认为是边缘。低于<code>threshold1</code>的任何值都被认为不是边缘。阈值1和阈值2之间的值基于其强度如何“连接”而被分类为边缘或非边缘。在这种情况下，任何低于30的梯度值都被认为是非边缘，而高于150的任何值都被认为是边缘。</p><p><img src="https://i.imgur.com/7F1fCp6.png" alt=""></p><p>请注意边缘是如何“更清晰”。与使用拉普拉斯算子或索贝尔梯度图像时相比，我们的噪声要少得多。此外，我们的硬币轮廓清晰显示。</p><p><strong>用到的函数</strong></p><p><span id="inline-blue">cv2.Laplacian</span></p><p><span id="inline-blue">np.uint8</span></p><p><span id="inline-blue">cv2.Sobel</span></p><p><span id="inline-blue">cv2.Canny</span></p><h3 id="更多的参考："><a href="#更多的参考：" class="headerlink" title="更多的参考："></a>更多的参考：</h3><p><a href="https://ppao.pyimagesearch.com/lessons/ppao-chapter-9-thresholding/" target="_blank" rel="noopener">PPaO Chapter 9 – Thresholding</a></p><p><a href="https://www.pyimagesearch.com/2015/04/06/zero-parameter-automatic-canny-edge-detection-with-python-and-opencv/" target="_blank" rel="noopener">Zero-parameter, automatic Canny edge detection with Python and OpenCV</a></p><p><a href="https://www.pyimagesearch.com/2014/11/10/histogram-oriented-gradients-object-detection/" target="_blank" rel="noopener">Histogram of Oriented Gradients and Object Detection</a></p><hr>]]></content>
    
    <summary type="html">
    
      第十三个代码
    
    </summary>
    
      <category term="计算机视觉" scheme="https://0Leo0.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="Opencv" scheme="https://0Leo0.github.io/tags/Opencv/"/>
    
  </entry>
  
  <entry>
    <title>OpenCV_python3_12</title>
    <link href="https://0Leo0.github.io//2018/OpenCV_python3_12.html"/>
    <id>https://0Leo0.github.io//2018/OpenCV_python3_12.html</id>
    <published>2018-11-23T15:17:50.000Z</published>
    <updated>2018-11-26T03:33:59.846Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><a id="more"></a><h2 id="Practical-Python-and-OpenCV-3rd-Edition-12"><a href="#Practical-Python-and-OpenCV-3rd-Edition-12" class="headerlink" title="Practical Python and OpenCV,3rd Edition 12"></a>Practical Python and OpenCV,3rd Edition 12</h2><hr><h3 id="Thresholding"><a href="#Thresholding" class="headerlink" title="Thresholding"></a>Thresholding</h3><p>阈值处理是图像的二值化。通常，我们寻求将灰度图像转换为二进制图像，其中像素为0或255</p><p>一个简单的阈值处理示例是选择像素值p，然后将小于p的所有像素强度设置为零，并将所有大于p像素值设置为255.这样，我们就能够创建图像的二进制表示。</p><p>通常，我们使用阈值处理来关注图像中特别感兴趣的对象或区域。使用阈值方法，我们将能够在图像中找到硬币。</p><h4 id="simple-thresholding"><a href="#simple-thresholding" class="headerlink" title="simple thresholding"></a>simple thresholding</h4><p>应用简单的阈值方法需要人为干预。我们必须指定阈值T.所有低于T的像素强度都设置为0.并且所有大于T的像素强度都设置为255</p><p>我们还可以通过将低于T的所有像素设置为255并且将所有大于T的像素强度设置为0来应用该二值化的逆。</p><p>新建一个simple_threholding.py文件</p><pre><code>import numpy as np import argparse import cv2 # Construct the argument parser and parse the argumentsap = argparse.ArgumentParser()ap.add_argument(&quot;-i&quot;, &quot;--image&quot;, required = True,    help = &quot;Path to the image&quot;)args = vars(ap.parse_args())# Load the image, convert it to grayscale, and blur it slightlyimage = cv2.imread(args[&quot;image&quot;])image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)blurred = cv2.GaussianBlur(image,(5,5),0)cv2.imshow(&quot;Image&quot;,image)</code></pre><p>我们导入我们的包，解析我们的参数，并加载我们的图像。然后我们将图像从RGB颜色空间转换为灰度。此时，我们应用高斯模糊，σ=5半径。应用高斯模糊有助于消除图像中我们不关心的一些高频边缘。</p><p><img src="https://i.imgur.com/eERLUxB.png" alt=""></p><pre><code>(T,thresh) = cv2.threshold(blurred,155,255,cv2.THRESH_BINARY)cv2.imshow(&quot;Threshold Binary&quot;,thresh)(T,threshInv) = cv2.threshold(blurred,155,255,cv2.THRESH_BINARY_INV)cv2.imshow(&quot;Threshold Binary Inverse&quot;,threshInv)cv2.imshow(&quot;Coins&quot;,cv2.bitwise_and(image,image,mask=threshInv))cv2.waitKey(0)</code></pre><p>在图像模糊后，我们使用<code>cv2.threshold</code>函数计算阈值图像。 此方法需要四个参数。第一个是我们希望阈值的灰度图像。我们在这里提供模糊图像。</p><p>然后，我们手动提供T阈值。我们使用T=155的值。</p><p>我们的第三个参数是在阈值处理期间应用的最大值。任何大于T的像素强度p都设置为该值。在我们的示例中，任何大于155的像素值都设置为255.任何小于155的值都设置为零。</p><p>最后，我们必须提供一种阈值方法。我们使用cv2.THRESH_BINARY方法，该方法指示大于T的像素值p被设置为最大值（第三个参数）。</p><p><code>cv2.threshold</code>函数返回两个值。第一个是T，我们为阈值手动指定的值。第二个是我们实际的阈值图像。</p><p>然后我们在上面左下中显示我们的阈值图像。我们可以看到我们的硬币现在是黑色像素，白色像素是背景。</p><p>接着，我们使用<code>cv2.THRESH_BINARY_INV</code>作为我们的阈值方法，应用逆阈值而不是正常的阈值。正如我们在上图右下角，我们的硬币现在是白色的，背景是黑色的。</p><p>我们要执行的最后一项任务是显示图像中的硬币并隐藏其他所有内容。</p><p>我们使用<code>cv2.bitwise_and</code>函数执行屏蔽。我们提供原始硬币图像作为前两个参数，然后我们的反转阈值图像作为我们的mask。请记住，mask仅考虑原始图像中mask大于零的像素。由于我们前面反转阈值图像在近似硬币所包含的区域方面做得很好，我们可以使用这个反转阈值图像作为我们的蒙版。</p><p>左上角，显示了应用我们mask的结果——硬币清晰显示，而其余图像被隐藏。</p><h4 id="adaptive-thresholding"><a href="#adaptive-thresholding" class="headerlink" title="adaptive thresholding"></a>adaptive thresholding</h4><p>使用简单阈值法的缺点之一是我们需要手动提供阈值T。寻找一个好的T值不仅需要大量的手动实验和参数调整，如果图像在像素强度方面显示出很多范围，则没有太大帮助。</p><p>为了克服这个问题，我们可以使用自适应阈值处理，它考虑像素的小邻域，然后为每个邻域找到最佳阈值T. 该方法允许我们处理可能存在显着范围的像素强度的情况，并且T的最佳值可以针对图像的不同部分而改变。</p><p>新建一个adaptive_thresholding.py文件</p><pre><code>import numpy as np import argparseimport cv2 ap = argparse.ArgumentParser()ap.add_argument(&quot;-i&quot;,&quot;--image&quot;,required=True,        help=&quot;path to the image&quot;)args = vars(ap.parse_args())# Load the image, convert it to grayscale, and blur it slightlyimage = cv2.imread(args[&quot;image&quot;])image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)blurred = cv2.GaussianBlur(image,(5,5,),0)cv2.imshow(&quot;Image&quot;,image)# In our previous example, we had to use manually specify a# pixel value to globally threshold the image. In this example# we are going to examine a neighborbood of pixels and adaptively# apply thresholding to each neighborbood. In this example, we&apos;ll# calculate the mean value of the neighborhood area of 11 pixels# and threshold based on that value. Finally, our constant C is# subtracted from the mean calculation (in this case 4)thresh = cv2.adaptiveThreshold(blurred,255,    cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY_INV,11,4)cv2.imshow(&quot;Mean Thresh&quot;,thresh)# We can also apply Gaussian thresholding in the same mannerthresh = cv2.adaptiveThreshold(blurred,255,    cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,15,3)cv2.imshow(&quot;Gaussian Thresh&quot;,thresh)cv2.waitKey(0)</code></pre><p>然后，我们使用<code>cv2.adaptiveThreshold</code>函数对我们的模糊图像应用自适应阈值。我们提供的第一个参数是我们想要阈值的图像。然后，我们提供最大值255，类似于上面提到的简单阈值。</p><p>第三个参数是我们计算当前像素邻域的阈值的方法。 通过提供<code>cv2.ADAPTIVE_THRESH_MEAN_C</code>，我们指出我们想要计算像素邻域的平均值并将其视为我们的T值。</p><p>接下来，我们需要我们的阈值方法。同样，该参数的描述与上述简单的阈值处理方法相同。 我们使用<code>cv2.THRESH_BINARY_INV</code>来指示邻域中任何大于T的像素强度应该设置为255，否则应该设置为0。</p><p>下一个参数是我们的邻域大小。此整数值必须为奇数，表示我们的像素邻域将有多大。我们提供的值为11，表明我们将检查图像的11×11像素区域，而不是像在简单的阈值方法中那样尝试全局阈值图像。</p><p>最后，我们提供一个简单称为C的参数。这个值是一个从均值中减去的整数，允许我们微调我们的阈值。我们在这个例子中使用C=4。</p><p><img src="https://i.imgur.com/s9enExH.png" alt=""></p><p>应用均值加权自适应阈值的结果可以在上图中间图像中看到。</p><p>除了应用标准平均阈值，我们也可以应用高斯(加权平均)阈值处理。但现在我们调整了一些值。我们使用<code>cv2.ADAPTIVE_THRESH_GAUSSIAN_C</code>来表示我们想要使用加权平均值，而不是提供<code>cv2.ADAPTIVE_THRESH_ MEAN_C</code>的值。我们还使用了15×15像素的邻域大小，而不是前面示例中的11×11邻域大小。我们还稍微改变了我们的C值（我们从平均值中减去的值）并使用3而不是4。</p><p>通常，在平均自适应阈值处理和高斯自适应阈值处理之间进行选择需要在您的最终进行一些实验。要改变的最重要的参数是邻域大小和C，您从平均值中减去的值。通过试验此值，您将能够显着更改阈值的结果。</p><h4 id="otsu-and-riddler-calvard"><a href="#otsu-and-riddler-calvard" class="headerlink" title="otsu and riddler-calvard"></a>otsu and riddler-calvard</h4><p>我们可以自动计算T的阈值的另一种方法是使用Otsu的方法。</p><p>Otsu的方法假设图像的灰度直方图中有两个峰值。然后它试图找到一个最佳值来分隔这两个峰值——也就是我们的T值。</p><p>虽然OpenCV为Otsu的方法提供了支持，但我更喜欢Luis Pedro Coelho在mahotas包中的实现，因为它更像是Pythonic。</p><p>新建一个otsu_and_riddler.py文件</p><pre><code>from __future__ import print_functionimport numpy as np import argparseimport mahotasimport cv2 ap = argparse.ArgumentParser()ap.add_argument(&quot;-i&quot;,&quot;--image&quot;,required=True,    help=&quot;path to the image&quot;)args = vars(ap.parse_args())image = cv2.imread(args[&quot;image&quot;])image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)blurred = cv2.GaussianBlur(image,(5,5),0)cv2.imshow(&quot;Image&quot;,image)# OpenCV provides methods to use Otsu&apos;s thresholding, but I find# the mahotas implementation is more &apos;Pythonic&apos;. Otsu&apos;s method# assumes that are two &apos;peaks&apos; in the grayscale histogram. It finds# these peaks, and then returns a value we should threshold on.T = mahotas.thresholding.otsu(blurred)print(&quot;Otsu&apos;s threshold:{}&quot;.format(T))</code></pre><p>我们这里引入了mahotas，另一个图像处理包。然后处理我们解析参数和加载图像的标准做法。</p><p>为了计算T的最佳值，我们在<code>mahotas.thresholding</code>包中使用otsu函数。 正如我们的输出稍后将向我们展示的那样，Otsu的方法找到了我们将用于阈值处理的T=137的值。</p><pre><code># Applying the threshold can be done using NumPy, where values# smaller than the threshold are set to zero, and values above# the threshold are set to 255 (white).thresh = image.copy()thresh[thresh &gt; T] = 255thresh[thresh &lt; 255] = 0thresh = cv2.bitwise_not(thresh)cv2.imshow(&quot;Otsu&quot;,thresh)# An alternative is to use the Riddler-Calvard methodT = mahotas.thresholding.rc(blurred)print(&quot;Riddler-Calvard:{}&quot;.format(T))thresh = image.copy()thresh[thresh &gt; T] = 255thresh[thresh &lt; 255] = 0thresh = cv2.bitwise_not(thresh)cv2.imshow(&quot;Riddler-Calvard&quot;,thresh)cv2.waitKey(0)</code></pre><p>应用阈值处理。首先，我们制作灰度图像的副本，以便我们有图像进行阈值。 然后，使任何值大于T的值都是white，接着将剩下的所有非白色的像素转换为黑色像素。然后我们使用<code>cv2.bitwise_not</code>来反转我们的阈值。这相当于应用<code>cv2.THRESH_BINARY_INV</code>阈值类型，如本章前面的例子。</p><p>Otsu方法的结果可以在下图的中间图像中看到。 我们可以清楚地看到图像中的硬币已经突出显示。</p><p>在找到T的最佳值时要记住的另一种方法是<code>Riddler-Calvard</code>方法。就像在Otsu的方法中一样，<code>Riddler-Calvard</code>方法也为T计算最佳值137.我们使用<code>mahotas.thresholding</code>中的<code>rc</code>函数应用此方法。如前面的例子中所示。鉴于<code>Otsu</code>和<code>Riddler-Calvard</code>的T值相同，下图右图中的阈值图像与中间的阈值图像相同。</p><p><img src="https://i.imgur.com/Uf5mCQM.png" alt=""></p><p><img src="https://i.imgur.com/S8lweCt.png" alt=""></p><p><strong>用到的函数</strong></p><p><span id="inline-blue">cv2.threshold</span></p><p><span id="inline-blue">cv2.THRESH_BINARY</span></p><p><span id="inline-blue">cv2.adaptiveThreshold</span></p><p><span id="inline-blue">cv2.THRESH_BINARY_INV</span></p><p><span id="inline-blue"></span></p><h3 id="更多的参考："><a href="#更多的参考：" class="headerlink" title="更多的参考："></a>更多的参考：</h3><p><a href="https://ppao.pyimagesearch.com/lessons/ppao-chapter-9-thresholding/" target="_blank" rel="noopener">PPaO Chapter 9 – Thresholding</a></p><p><a href="https://www.pyimagesearch.com/2014/09/08/thresholding-simple-image-segmentation-using-opencv/" target="_blank" rel="noopener">Thresholding: Simple Image Segmentation using OpenCV</a></p><p><a href="https://www.pyimagesearch.com/2015/11/02/watershed-opencv/" target="_blank" rel="noopener">Watershed OpenCV</a></p><hr>]]></content>
    
    <summary type="html">
    
      第十二个代码
    
    </summary>
    
      <category term="计算机视觉" scheme="https://0Leo0.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="Opencv" scheme="https://0Leo0.github.io/tags/Opencv/"/>
    
  </entry>
  
  <entry>
    <title>OpenCV_python3_11</title>
    <link href="https://0Leo0.github.io//2018/OpenCV_python3_11.html"/>
    <id>https://0Leo0.github.io//2018/OpenCV_python3_11.html</id>
    <published>2018-11-23T13:17:50.000Z</published>
    <updated>2018-11-25T07:01:53.679Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><a id="more"></a><h2 id="Practical-Python-and-OpenCV-3rd-Edition-11"><a href="#Practical-Python-and-OpenCV-3rd-Edition-11" class="headerlink" title="Practical Python and OpenCV,3rd Edition 11"></a>Practical Python and OpenCV,3rd Edition 11</h2><hr><h3 id="smoothing-and-blurring"><a href="#smoothing-and-blurring" class="headerlink" title="smoothing and blurring"></a>smoothing and blurring</h3><p>我很确定我们都知道模糊是什么。当您的相机拍摄失焦时会发生这种情况。图像中较清晰的区域会丢失其细节，通常为圆盘/圆形。</p><p>实际上，这意味着图像中的每个像素与其周围的像素强度混合在一起。邻域中像素的这种“混合”成为我们模糊的像素。</p><p>虽然这种效果在我们的照片中通常是不受欢迎的，但在执行图像处理任务时它实际上非常有用。</p><p>新建一个blurring.py文件</p><h4 id="averaging"><a href="#averaging" class="headerlink" title="averaging"></a>averaging</h4><p>我们要探索的第一个模糊方法是平均。</p><p>顾名思义，我们将在图像顶部定义一个k×k滑动窗口，其中k始终为奇数。此窗口将从左到右，从上到下滑动。然后将该矩阵中心的像素（我们必须使用奇数，否则不会有真正的“中心”）设置为围绕它的所有其他像素的平均值。</p><p>我们将此滑动窗口称为“卷积内核”或仅称为“内核”。我们将在本章中继续使用这个术语。</p><p>正如我们将看到的，随着内核大小的增加，我们的图像变得越模糊。</p><pre><code># Let&apos;s apply standard &quot;averaging&quot; blurring first. Average# blurring (as the name suggests), takes the average of all# pixels in the surrounding area and replaces the centeral# element of the output image with the average. Thus, in# order to have a central element, the area surrounding the# central must be odd. Here are a few examples with varying# kernel sizes. Notice how the larger the kernel gets, the# more blurred the image becomesblurred = np.hstack([    cv2.blur(image,(3,3)),    cv2.blur(image,(5,5)),    cv2.blur(image,(7,7))])cv2.imshow(&quot;Averaged&quot;,blurred)cv2.waitKey(0)</code></pre><p><img src="https://i.imgur.com/7qWer9Y.png" alt=""></p><p><img src="https://i.imgur.com/F717L9U.png" alt=""></p><p>使用3×3内核(左)，5×5内核(中)和7×7内核(右)执行平均模糊</p><p>为了平均模糊图像，我们使用<code>cv2.blur</code>函数。此函数需要两个参数：我们想要模糊的图像和内核的大小。我们使用不同大小的内核来模糊我们的图像。我们的内核越大，我们的图像就越模糊</p><p>我们使用<code>np.hstack</code>函数将输出图像堆叠在一起。此方法将我们的三个图像“水平堆叠”成一行。这很有用，因为我们不想使用<code>cv2.imshow</code>函数创建三个单独的窗口。</p><h4 id="Gaussian"><a href="#Gaussian" class="headerlink" title="Gaussian"></a>Gaussian</h4><p>接下来，我们将回顾高斯模糊。高斯模糊类似于平均模糊，但是我们现在使用加权平均值而不是使用简单均值，其中更接近中心像素的邻域像素对平均值贡献更多“权重”。</p><p>最终结果是我们的图像比使用上一节中讨论的平均方法更少模糊，但更自然地模糊。</p><p>继续前面的blurring.py编写</p><pre><code># We can also apply Gaussian blurring, where the relevant# parameters are the image we want to blur and the standard# deviation in the X and Y direction. Again, as the standard# deviation size increases, the image becomes progressively# more blurredblurred = np.hstack([    cv2.GaussianBlur(image,(3,3),0),    cv2.GaussianBlur(image,(5,5),0),    cv2.GaussianBlur(image,(7,7),0)])cv2.imshow(&quot;Gaussian&quot;,blurred)cv2.waitKey(0)</code></pre><p>显示结果：</p><p><img src="https://i.imgur.com/GFwqFeX.png" alt=""></p><p>在这里你可以看到我们正在使用cv2.GaussianBlur函数。函数的第一个参数是我们想要模糊的图像。然后，类似于cv2.blur，我们提供一个表示内核大小的元组。同样，我们从3×3的小内核开始，并开始增加它到7x7。</p><p>最后一个参数是我们的σ，即x轴方向的标准偏差。通过将此值设置为0，我们指示OpenCV根据内核大小自动计算它们。</p><p>我们可以在上图看到高斯模糊的输出。与使用平均方法相比，我们的图像具有更少的模糊效果; 然而，由于加权平均值的计算，模糊本身更自然，而不是允许内核邻域中的所有像素具有相等的权重。</p><h4 id="Median"><a href="#Median" class="headerlink" title="Median"></a>Median</h4><p>传统上，中值模糊方法在去除椒盐噪声时最有效。这种类型的噪音正是它听起来的样子：想象一下拍照，把它放在餐桌上，然后在上面洒上盐和胡椒。 使用中值模糊方法，您可以从图像中删除盐和胡椒。</p><p>在应用中值模糊时，我们首先定义内核大小k。然后，如在平均模糊方法中，我们考虑大小为k×k的邻域中的所有像素。但是，与平均方法不同，我们不是用邻域的平均值替换中心像素，而是用邻域的中值替换中心像素。</p><p>中值模糊在去除图像中的盐和胡椒样式噪声方面更有效，因为每个中心像素总是被图像中存在的像素强度替换。</p><p>平均和高斯方法可以计算邻域的平均值或加权平均值——该平均像素强度可能存在于邻域中，也可能不存在。但根据定义，中间像素必须存在于我们的邻域中。通过用中值而不是平均值替换我们的中心像素，我们可以大大降低噪声。</p><pre><code># The cv2.medianBlur function is mainly used for removing# what is called &quot;salt-and-pepper&quot; noise. Unlike the Average# method mentioned above, the median method (as the name# suggests), calculates the median pixel value amongst the# surrounding area.blurred = np.hstack([    cv2.medianBlur(image,3),    cv2.medianBlur(image,5),    cv2.medianBlur(image,7)])cv2.imshow(&quot;Median&quot;,blurred)cv2.waitKey(0)</code></pre><p>显示效果：</p><p><img src="https://i.imgur.com/pN5WIiD.png" alt=""></p><p>通过调用cv2.medianBlur函数来实现应用中值模糊。此方法有两个参数：我们想要模糊的图像和内核的大小。我们从内核大小3开始，然后将其增加到5和7。</p><h4 id="bilateral"><a href="#bilateral" class="headerlink" title="bilateral"></a>bilateral</h4><p>我们要探索的最后一种方法是双边模糊。</p><p>到目前为止，我们的模糊方法的目的是减少图像中的噪声和细节; 但是，我们往往会丢失图像中的边缘。</p><p>为了在保持边缘的同时降低噪音，我们可以使用双边模糊。双边模糊通过引入两个高斯分布来实现这一点。</p><p>第一高斯函数仅考虑空间邻居，即在图像的(x，y)坐标空间中出现在一起的像素。然后，第二高斯模型对邻域的像素强度进行建模，确保在模糊的实际计算中仅包括具有相似强度的像素。</p><p>总的来说，这种方法能够保留图像的边缘，同时还能降低噪点。这种方法的最大缺点是它比平均，高斯和中值模糊对应物慢得多。</p><pre><code># You may have noticed that blurring can help remove noise,# but also makes edge less sharp. In order to keep edges# sharp, we can use bilateral filtering. We need to specify# the diameter of the neighborhood (as in examples above),# along with sigma values for color and coordinate space.# The larger these sigma values, the more pixels will be# considered within the neighborhood.blurred = np.hstack([    cv2.bilateralFilter(image,5,21,21),    cv2.bilateralFilter(image,7,31,31),    cv2.bilateralFilter(image,9,41,41)])cv2.imshow(&quot;Bilateral&quot;,blurred)cv2.waitKey(0)</code></pre><p>显示效果：</p><p><img src="https://i.imgur.com/alLDzzm.png" alt=""></p><p>我们通过调用cv2.bilateralFilter函数来应用双边模糊。我们提供的第一个参数是我们想要模糊的图像。然后，我们需要定义像素邻域的直径。第三个参数是我们的颜色σ。颜色σ的值越大意味着在计算模糊时将考虑邻域中的更多颜色。最后，我们需要提供空间σ。较大的空间值σ意味着距离中心像素较远的像素将影响模糊计算，前提是它们的颜色足够相似。</p><p><strong>用到的函数</strong></p><p><span id="inline-blue">np.hstack</span></p><p><span id="inline-blue">cv2.blur</span></p><p><span id="inline-blue">cv2.GaussianBlur</span></p><p><span id="inline-blue">cv2.medianBlur</span></p><p><span id="inline-blue">cv2.bilateralFilter</span></p><h3 id="更多的参考："><a href="#更多的参考：" class="headerlink" title="更多的参考："></a>更多的参考：</h3><p><a href="https://blog.csdn.net/csdn15698845876/article/details/73380803" target="_blank" rel="noopener">Numpy中stack()，hstack()，vstack()函数详解</a></p><p><a href="https://ppao.pyimagesearch.com/lessons/ppao-chapter-8-smoothing-and-blurring/" target="_blank" rel="noopener">PPaO Chapter 8——Smoothing and Blurring</a></p><hr>]]></content>
    
    <summary type="html">
    
      第十一个代码
    
    </summary>
    
      <category term="计算机视觉" scheme="https://0Leo0.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="Opencv" scheme="https://0Leo0.github.io/tags/Opencv/"/>
    
  </entry>
  
  <entry>
    <title>OpenCV_python3_10</title>
    <link href="https://0Leo0.github.io//2018/OpenCV_python3_10.html"/>
    <id>https://0Leo0.github.io//2018/OpenCV_python3_10.html</id>
    <published>2018-11-22T13:17:50.000Z</published>
    <updated>2018-11-23T10:45:05.726Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><a id="more"></a><h2 id="Practical-Python-and-OpenCV-3rd-Edition-10"><a href="#Practical-Python-and-OpenCV-3rd-Edition-10" class="headerlink" title="Practical Python and OpenCV,3rd Edition 10"></a>Practical Python and OpenCV,3rd Edition 10</h2><hr><h3 id="直方图-historams"><a href="#直方图-historams" class="headerlink" title="直方图(historams)"></a>直方图(historams)</h3><p>那么，直方图到底是什么？直方图表示图像中像素强度（无论是彩色还是灰度）的分布。它可以被可视化为给出强度（像素值）分布的高级直观的图表(graph)(或绘图(plot)) 在本例中，我们将假设RGB颜色空间，因此这些像素值将在0到255的范围内。</p><p>绘制直方图时，X轴作为我们的“箱(bins)”。如果我们构造一个有256个bins的直方图，那么我们就可以有效地计算每个像素值出现的次数。相反，如果我们仅使用2个(等间隔)二进制位，那么我们计算一个像素在[0,128]或[128,255]范围内的次数。The number of pixels binned<br>to the x-axis value is then plotted on the y-axis.</p><p>通过简单地检查图像的直方图，您可以大致了解对比度，亮度和强度分布。</p><h4 id="using-opencv-to-compute-histograms"><a href="#using-opencv-to-compute-histograms" class="headerlink" title="using opencv to compute histograms"></a>using opencv to compute histograms</h4><p>我们将使用cv2.calcHist函数来构建直方图。 在我们进入任何代码示例之前，让我们快速回顾一下这个函数：</p><p><code>cv2.calcHist(images,channels,mask,histSize,ranges)</code></p><p><strong>images</strong>: 我们想要计算直方图的图像，wrap it as a list:[myImage].</p><p><strong>channels</strong>: 这是索引列表，我们在其中指定要为其计算直方图的通道的索引。要计算灰度图像的直方图，列表将为[0]。要计算所有三个红色，绿色和蓝色通道的直方图，通道列表将为[0,1,2]。</p><p><strong>mask</strong>：如果提供mask，则仅计算mask像素的直方图。如果我们没有mask或者不想应用mask，我们可以提供None值。</p><p><strong>histSize</strong>：这是我们在计算直方图时要使用的bins。同样，这是一个列表，我们正在为每个通道计算一个直方图。bins尺寸并非都必须相同。以下是每个通道分配32个bins的示例：[32,32,32]。</p><p><strong>ranges</strong>：这里我们指定可能的像素值的范围。通常，对于每个通道，这是[0,256]，但如果您使用RGB以外的颜色空间(例如HSV)，则范围可能不同。</p><h4 id="grayscale-histograms"><a href="#grayscale-histograms" class="headerlink" title="grayscale histograms"></a>grayscale histograms</h4><pre><code>from matplotlib import pyplot as plt import argparse import cv2 ap = argparse.ArgumentParser()ap.add_argument(&apos;-i&apos;,&quot;--image&quot;,required=True,    help=&quot;path to the image&quot;)args = vars(ap.parse_args())image = cv2.imread(args[&quot;image&quot;])image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)cv2.imshow(&quot;Original&quot;,image)</code></pre><p><strong>解释</strong>：导入必要的库，显示原始图像并转为灰度图</p><pre><code>hist = cv2.calcHist([image],[0],None,[256],[0,256])plt.figure()plt.title(&quot;Grayscale Histogram&quot;)plt.xlabel(&quot;Bins&quot;)plt.ylabel(&quot;# of Pixels&quot;)plt.plot(hist)plt.xlim([0,256])plt.show()cv2.waitKey(0)</code></pre><p><strong>解释</strong>：现在事情变得有趣了。我们计算实际直方图。参考前面的参数解释，这里，我们可以看到我们的第一个参数是灰度图像。灰度图像只有一个通道，因此通道的值为[0]。我们没有mask，因此我们将掩码值设置为None。我们将在直方图中使用256个bin，可能的值范围为0到256。</p><p>显示结果:</p><p><img src="https://i.imgur.com/fJ1hrhH.png" alt=""></p><p><img src="https://i.imgur.com/uuqVv6P.png" alt=""></p><p><strong>解释</strong>：我们如何解释这个直方图？bins(0-255)绘制在x轴上。并且y轴计算每个bin中的像素数。大多数像素落在大约60到120的范围内。查看直方图的右尾，我们看到200到255范围内的像素非常少。这意味着图像中只有很少的“白色”像素。</p><h4 id="color-histograms"><a href="#color-histograms" class="headerlink" title="color histograms"></a>color histograms</h4><pre><code>from __future__ import print_functionfrom matplotlib import pyplot as plt import numpy as np import argparseimport cv2 ap = argparse.ArgumentParser()ap.add_argument(&apos;-i&apos;,&quot;--image&quot;,required=True,    help=&quot;path to the image&quot;)args = vars(ap.parse_args())image = cv2.imread(args[&quot;image&quot;])cv2.imshow(&quot;Original&quot;,image)#Grab the image channels, initialize the tuple of colors#and the figurechans = cv2.split(image)colors = (&quot;b&quot;,&quot;g&quot;,&quot;r&quot;)plt.figure()plt.title(&quot;&apos;Flattened&apos; Color Histogram&quot;)plt.xlabel(&quot;Bins&quot;)plt.ylabel(&quot;# of Pixels&quot;)#Loop over the image channelsfor (chan,color) in zip(chans,colors):    #Create a histogram for the current channel and plot it    hist = cv2.calcHist([chan],[0],None,[256],[0,256])    plt.plot(hist,color=color)    plt.xlim([0,256])    plt.show()</code></pre><p>我们要做的第一件事是将图像分成三个通道：蓝色，绿色和红色。通常，我们读到这是红色，绿色，蓝色(RGB)。但是，OpenCV以相反的顺序将图像存储为NumPy数组：BGR。这一点很重要 然后我们初始化一个代表颜色的字符串元组。接着我们设置了PyPlot图。我们将在x轴上绘制bins，并在y轴上绘制放置在每个bin中的像素数量。</p><p>然后我们进行for循环，在循环里，我们开始循环遍历图像中的每个通道。然后，对于每个通道，我们计算直方图。该代码与计算灰度图像的直方图的代码相同; 但是，我们正在为每个红色，绿色和蓝色通道执行此操作，使我们能够表征像素强度的分布。</p><p><img src="https://i.imgur.com/qACDpX8.png" alt=""></p><p><img src="https://i.imgur.com/l3fLSFR.png" alt=""></p><p>我们可以在上图中检查我们的颜色直方图。我们看到在bin 100周围的绿色直方图中存在尖峰。这表示在beach图像中的树木以及绿色植被有一个 darker green value。</p><p>我们还看到170到225范围内有很多蓝色像素。考虑到这些像素要lighter得多，我们知道它们来自我们海滩图像中的蓝天。同样地，我们看到25到50范围内的蓝色像素范围要小得多——这些像素更暗，因此是图像左下角的海洋像素。</p><p>到目前为止，我们一次只计算了一个通道的直方图。 现在我们继续进行多维直方图，并一次考虑两个通道。我喜欢用单词AND来解释多维直方图。</p><p>例如，我们可以提出一个问题，例如“有多少像素的红色值为10，蓝色值为30？”。有多少像素的绿色值为200，红色值为130？通过使用连接AND，我们能够构建多维直方图。</p><pre><code>#Let&apos;s move on to 2D histograms -- I am reducing the#number of bins in the histogram from 256 to 32 so we#can better visualize the resultsfig = plt.figure()#Plot a 2D color histogram for green and blueax = fig.add_subplot(131)hist = cv2.calcHist([chans[1],chans[0]],[0,1],None,        [32,32],[0,256,0,256])p = ax.imshow(hist,interpolation=&quot;nearest&quot;)ax.set_title(&quot;2D Color Histogram for G and B&quot;)plt.colorbar(p)#Plot a 2D color histogram for green and redax = fig.add_subplot(132)hist = cv2.calcHist([chans[1],chans[2]],[0,1],None,        [32,32],[0,256,0,256])p = ax.imshow(hist,interpolation=&quot;nearest&quot;)ax.set_title(&quot;2D Color Histogram for G and R&quot;)plt.colorbar(p)#Plot a 2D color histogram for blue and redax = fig.add_subplot(133)hist = cv2.calcHist([chans[0],chans[2]],[0,1],None,        [32,32],[0,256,0,256])p = ax.imshow(hist,interpolation=&quot;nearest&quot;)ax.set_title(&quot;2D Color Histogram for B and R&quot;)plt.colorbar(p)print(&quot;2D histogram shape : {}, with {} values&quot;.format(    hist.shape,hist.flatten().shape[0]))</code></pre><p>现在我们正在使用多维直方图，我们需要记住我们正在使用的bins的数量。在前面的例子中，我使用了256个bins来进行演示。但是，如果我们在2D直方图中为每个维度使用256个二进制位，则我们得到的直方图将具有256×256=65,536个单独的像素计数。这不仅浪费资源，而且不实用。 在计算多维直方图时，大多数应用程序使用8到64个区间。上面使用32个bins而不是256个bins。</p><p>通过检查cv2.calcHist函数的第一个参数，可以看出此代码中最重要的内容。在这里，我们看到我们传递了两个通道的列表：绿色和蓝色通道。 </p><p>那么，如何在OpenCV中存储2D直方图？它实际上是一个2D NumPy数组。 由于我为每个通道使用了32个bin，我现在有一个32×32的直方图。</p><p>我们如何可视化2D直方图？如下图所示，其中我们看到三个图。第一个是绿色和蓝色通道的2D颜色直方图，第二个是绿色和红色，第三个是蓝色和红色。蓝色阴影表示低像素计数，而红色阴影表示大像素计数(即，2D直方图中的峰值)。我们倾向于在绿色和蓝色直方图中看到许多峰，其中x=22且y=12.这对应于植被和树木的绿色像素以及天空和海洋的蓝色。</p><p><img src="https://i.imgur.com/MAhIC4H.png" alt=""></p><p>print输出：</p><p><code>2D histogram shape : (32, 32), with 1024 values</code></p><p>使用2D直方图一次考虑两个通道。但是，如果我们想要考虑所有三个RGB通道呢？</p><pre><code># Our 2D histogram could only take into account 2 out# of the 3 channels in the image so now let&apos;s build a# 3D color histogram (utilizing all channels) with 8 bins# in each direction -- we can&apos;t plot the 3D histogram, but# the theory is exactly like that of a 2D histogram, so# we&apos;ll just show the shape of the histogramhist = cv2.calcHist([image], [0, 1, 2],    None, [8, 8, 8], [0, 256, 0, 256, 0, 256])print(&quot;3D histogram shape: {}, with {} values&quot;.format(    hist.shape, hist.flatten().shape[0]))# Show our plotsplt.show()</code></pre><p>print输出：</p><p><code>3D histogram shape: (8, 8, 8), with 512 values</code></p><p>这里的代码非常简单——它只是上面代码的扩展。我们现在为每个RGB通道计算8×8×8直方图。我们无法想象这个直方图，但我们可以看到形状确实是(8,8,8)，有512个值。</p><h4 id="histogram-equalization-直方图均衡化"><a href="#histogram-equalization-直方图均衡化" class="headerlink" title="histogram equalization(直方图均衡化)"></a>histogram equalization(直方图均衡化)</h4><p>直方图均衡化通过“拉伸”像素的分布来改善图像的对比度。考虑一个在直方图中心有一个大峰值的。应用直方图均衡会将峰值拉伸到图像的角落，从而改善图像的整体对比度。直方图均衡应用于灰度图像。</p><p>当图像包含前景和背景都是dark或两者都是light时，此方法很有用。它往往会在照片中产生不切实际的影响; 但是，在增强医学或卫星图像的对比度时通常很有用。</p><p>新建一个equalize.py文本</p><pre><code>import numpy as np import argparseimport cv2 ap = argparse.ArgumentParser()ap.add_argument(&apos;-i&apos;,&quot;--image&quot;,required=True,    help=&quot;path to the image&quot;)args = vars(ap.parse_args())# Load the image and convert it to grayscaleimage = cv2.imread(args[&quot;image&quot;])image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)# Apply histogram equalization to stretch the constrast# of our imageeq = cv2.equalizeHist(image)# Show our images -- notice how the constrast of the second# image has been stretchedcv2.imshow(&quot;Histogram Equalization&quot;,np.hstack([image,eq]))cv2.waitKey(0)</code></pre><p><strong>解释</strong>：使用单个函数执行直方图均衡：cv2.equalizeHist，它接受单个参数，即我们想要执行直方图均衡的灰度图像。最后几行代码显示我们的直方图均衡图像。</p><p><img src="https://i.imgur.com/rwcz0NM.png" alt=""></p><p>在左边，我们有原始的海滩图像 然后，在右边，我们有直方图均衡的海滩图像。注意图像的对比度是如何彻底改变的，现在跨越[0,255]的整个范围。</p><h4 id="histograms-and-masks"><a href="#histograms-and-masks" class="headerlink" title="histograms and masks"></a>histograms and masks</h4><p>我们现在将构建一个mask并仅计算mask区域的颜色直方图。</p><p>新建一个histogram_with_mask.py文件</p><pre><code>from matplotlib import pyplot as plt import numpy as np import argparseimport cv2 def plot_histogram(image,title,mask = None):    chans = cv2.split(image)    colors = (&quot;b&quot;,&quot;g&quot;,&quot;r&quot;)    plt.figure()    plt.title(title)    plt.xlabel(&quot;Bins&quot;)    plt.ylabel(&quot;# of Pixels&quot;)    # Grab the image channels, initialize the tuple of colors    # and the figure    for (chan,color) in zip(chans,colors):        hist = cv2.calcHist([chan],[0],mask,[256],[0,256])        plt.plot(hist,color=color)        plt.xlim([0,256])</code></pre><p>我们定义plot_histogram。此函数接受三个参数：图像，绘图标题和掩码。如果我们没有图像mask，则mask默认为None。</p><p>plot_histogram函数的主体只是为图像中的每个通道计算直方图并绘制它。既然我们有一个函数来帮助我们轻松绘制直方图，那么让我们进入大部分代码：</p><pre><code>ap = argparse.ArgumentParser()ap.add_argument(&apos;-i&apos;,&quot;--image&quot;,required=True,    help=&quot;path to the image&quot;)args = vars(ap.parse_args())image = cv2.imread(args[&quot;image&quot;])cv2.imshow(&quot;Original&quot;,image)plot_histogram(image,&quot;Histogram for Original Image&quot;)# Construct a mask for our image -- our mask will be BLACK for# regions we want to IGNORE and WHITE for regions we want to# EXAMINE. In this example we will be examining the foliage# of the image, so we&apos;ll draw a white rectangle where the foliage# ismask = np.zeros(image.shape[:2],dtype=&quot;uint8&quot;)cv2.rectangle(mask,(15,15),(130,100),255,-1)cv2.imshow(&quot;Mask&quot;,mask)masked = cv2.bitwise_and(image,image,mask=mask)cv2.imshow(&quot;Applying the Mask&quot;,masked)cv2.waitKey(0)</code></pre><p><strong>结果</strong>：</p><p><img src="https://i.imgur.com/Sco8pbe.png" alt=""></p><p>现在我们准备为图像构建一个mask。我们将mask定义为NumPy数组，其宽度和高度与海滩图像相同。然后，我们从点（15,15）到点（130,100）绘制一个白色矩形。这个矩形将用作我们的蒙版——在直方图计算中仅将属于蒙版区域的像素进行直方图计算。</p><p>为了可视化我们的蒙版，我们对海滩图像应用按位AND，其结果可以上图中看到。注意中间的图像只是一个白色矩形，但是当我们将mask应用到海滩图像时，我们只看到蓝天(最右)。</p><pre><code># Let&apos;s compute a histogram for our image, but we&apos;ll only include# pixels in the masked regionplot_histogram(image, &quot;Histogram for Masked Image&quot;, mask = mask)# Show our plotsplt.show()</code></pre><p>最后，我们使用plot_histogram函数为我们的蒙版图像计算直方图并显示我们的结果。</p><p>结果：</p><p><img src="https://i.imgur.com/X28Ksij.png" alt=""></p><p>我们可以在上图中看到我们的蒙版直方图。大多数红色像素落在[0,80]范围内，表明红色像素对我们的图像贡献很小。这是有道理的，因为我们的天空是蓝色的。然后存在绿色像素，但是再次朝向RGB光谱的较暗端。最后，我们的蓝色像素落在更亮的范围内，显然是我们的蓝天。</p><p>最重要的是，将上图的蒙版颜色直方图与上面没有应用mask的颜色直方图进行比较。注意颜色直方图有多么不同。通过使用mask，我们只能将计算应用于我们感兴趣的图像的特定区域——在这个例子中，我们只是想检查蓝天的分布。</p><p><strong>用到的函数</strong></p><p><span id="inline-blue">cv2.calcHist</span></p><p><span id="inline-blue">add_subplot</span></p><p><span id="inline-blue">colorbar</span></p><p><span id="inline-blue">cv2.equalizeHist</span></p><h3 id="更多的参考："><a href="#更多的参考：" class="headerlink" title="更多的参考："></a>更多的参考：</h3><p><a href="https://ppao.pyimagesearch.com/lessons/ppao-chapter-7-histograms/" target="_blank" rel="noopener">PPaO Chapter 7 – Histograms</a></p><p><a href="https://matplotlib.org/" target="_blank" rel="noopener">matplotlib</a></p><p><a href="https://www.pyimagesearch.com/2014/07/14/3-ways-compare-histograms-using-opencv-python/" target="_blank" rel="noopener">How-To: 3 Ways to Compare Histograms using OpenCV and Python</a></p><p><a href="https://www.pyimagesearch.com/2014/12/01/complete-guide-building-image-search-engine-python-opencv/" target="_blank" rel="noopener">The complete guide to building an image search engine with Python and OpenCV</a></p><p><a href="https://www.pyimagesearch.com/2014/10/27/opencv-shape-descriptor-hu-moments-example/" target="_blank" rel="noopener">OpenCV Shape Descriptor: Hu Moments Example</a></p><p><a href="https://www.pyimagesearch.com/2014/04/07/building-pokedex-python-indexing-sprites-using-shape-descriptors-step-3-6/" target="_blank" rel="noopener">Building a Pokedex in Python: Indexing our Sprites using Shape Descriptors (Step 3 of 6)</a></p><hr>]]></content>
    
    <summary type="html">
    
      第十个代码
    
    </summary>
    
      <category term="计算机视觉" scheme="https://0Leo0.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="Opencv" scheme="https://0Leo0.github.io/tags/Opencv/"/>
    
  </entry>
  
  <entry>
    <title>OpenCV_python3_09</title>
    <link href="https://0Leo0.github.io//2018/OpenCV_python3_09.html"/>
    <id>https://0Leo0.github.io//2018/OpenCV_python3_09.html</id>
    <published>2018-11-22T03:17:50.000Z</published>
    <updated>2018-11-22T06:36:33.801Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><a id="more"></a><h2 id="Practical-Python-and-OpenCV-3rd-Edition-09"><a href="#Practical-Python-and-OpenCV-3rd-Edition-09" class="headerlink" title="Practical Python and OpenCV,3rd Edition 09"></a>Practical Python and OpenCV,3rd Edition 09</h2><hr><h3 id="颜色空间-color-spaces"><a href="#颜色空间-color-spaces" class="headerlink" title="颜色空间(color spaces)"></a>颜色空间(color spaces)</h3><p>前面我们探讨了RGB颜色空间，但是还有许多其他的颜色空间我们可以利用。</p><p><code>Hue-Saturation-Value</code>(色调-饱和度-值)(HSV)色彩空间更类似于人类思考和设想色彩的方式。然后是Lab颜色空间，它更适合人类感知颜色的方式。</p><p>新建一个colorspaces.py</p><pre><code># Construct the argument parser and parse the argumentsap = argparse.ArgumentParser()ap.add_argument(&apos;-i&apos;,&quot;--image&quot;,required=True,    help=&quot;path ot the image&quot;)args = vars(ap.parse_args())# Load the image and show itimage = cv2.imread(args[&quot;image&quot;])cv2.imshow(&quot;Original&quot;,image)</code></pre><p>读取输入参数，显示原始图片。</p><pre><code># Convert the image to grayscalegray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)cv2.imshow(&quot;Gray&quot;,gray)# Convert the image to the HSV (Hue, Saturation, Value)# color spaceshsv = cv2.cvtColor(image,cv2.COLOR_BGR2HSV)cv2.imshow(&quot;HSV&quot;,hsv)lab = cv2.cvtColor(image,cv2.COLOR_BGR2LAB)cv2.imshow(&quot;L*a*b&quot;,lab)cv2.waitKey(0)</code></pre><p>我们通过指定<code>cv2.COLOR_BGR2GRAY</code> 标志将图像从RGB颜色空间转换为灰度。通过指定<code>cv2.COLOR_BGR2HSV</code>标志，将图像转换为HSV颜色空间。最后，我们使用<code>cv2.COLOR_BGR2LAB</code>标志转换为Lab颜色空间。</p><p>显示效果：</p><p><img src="https://i.imgur.com/Fd3Y31A.png" alt=""></p><p><strong>用到的函数</strong></p><p><span id="inline-blue">cv2.cvtColor</span></p><h3 id="更多的参考："><a href="#更多的参考：" class="headerlink" title="更多的参考："></a>更多的参考：</h3><p><a href="https://ppao.pyimagesearch.com/lessons/ppao-chapter-6-image-processing/" target="_blank" rel="noopener">PPaO Chapter 6 – Image Processing</a></p><p><a href="https://www.pyimagesearch.com/2014/01/20/basic-image-manipulations-in-python-and-opencv-resizing-scaling-rotating-and-cropping/" target="_blank" rel="noopener">Basic Image Manipulations in Python and OpenCV</a></p><p><a href="https://www.pyimagesearch.com/2014/05/26/opencv-python-k-means-color-clustering/" target="_blank" rel="noopener">OpenCV and Python K-Means Color Clustering</a></p><p><a href="https://www.pyimagesearch.com/2014/07/07/color-quantization-opencv-using-k-means-clustering/" target="_blank" rel="noopener">Color Quantization with OpenCV using K-Means Clustering</a></p><p><a href="http://www.pyimagesearch.com/2014/06/30/super-fast-color-transfer-images/" target="_blank" rel="noopener">Super fast color transfer between images</a></p><p><a href="https://www.pyimagesearch.com/2015/09/14/ball-tracking-with-opencv/" target="_blank" rel="noopener">Ball Tracking with OpenCV</a></p><p><a href="https://www.pyimagesearch.com/2014/12/01/complete-guide-building-image-search-engine-python-opencv/" target="_blank" rel="noopener">The complete guide to building an image search engine with Python and OpenCV</a></p><p><a href="https://www.pyimagesearch.com/2014/08/18/skin-detection-step-step-example-using-python-opencv/" target="_blank" rel="noopener">Skin Detection: A Step-by-Step Example using Python and OpenCV</a></p><hr>]]></content>
    
    <summary type="html">
    
      第九个代码
    
    </summary>
    
      <category term="计算机视觉" scheme="https://0Leo0.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="Opencv" scheme="https://0Leo0.github.io/tags/Opencv/"/>
    
  </entry>
  
  <entry>
    <title>OpenCV_python3_08</title>
    <link href="https://0Leo0.github.io//2018/OpenCV_python3_08.html"/>
    <id>https://0Leo0.github.io//2018/OpenCV_python3_08.html</id>
    <published>2018-11-21T13:17:50.000Z</published>
    <updated>2018-11-22T03:17:21.750Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><a id="more"></a><h2 id="Practical-Python-and-OpenCV-3rd-Edition-08"><a href="#Practical-Python-and-OpenCV-3rd-Edition-08" class="headerlink" title="Practical Python and OpenCV,3rd Edition 08"></a>Practical Python and OpenCV,3rd Edition 08</h2><hr><h3 id="拆分和合并通道-splitting-and-merging-channels"><a href="#拆分和合并通道-splitting-and-merging-channels" class="headerlink" title="拆分和合并通道(splitting and merging channels)"></a>拆分和合并通道(splitting and merging channels)</h3><p>彩色图像由多个通道组成：红色，绿色和蓝色成分。我们已经看到我们可以通过索引到NumPy数组来访问这些成分。但是，如果我们想将图像分割成各自的成分呢？</p><p>我们将使用cv2.split函数。如下图所示，我们有下面一个图像，</p><p><img src="https://i.imgur.com/NYAxEld.png" alt=""></p><p>这张图片非常的蓝，编写代码，实现通道的提取</p><p>新建一个splitting_and_merging.py</p><pre><code>import numpy as np import argparseimport cv2 # Construct the argument parser and parse the argumentsap = argparse.ArgumentParser()ap.add_argument(&apos;-i&apos;,&quot;--image&quot;,required=True,    help=&quot;path to the image&quot;)args = vars(ap.parse_args())</code></pre><p>上面读取输入参数。</p><pre><code># Load the image and grab each channel: Red, Green, and Blue# NOTE: OpenCV stores an image as NumPy array with its# channels in reverse order! When we call cv2.split, we are# actually getting the channels as Blue, Green, Red!image = cv2.imread(args[&quot;image&quot;])(B,G,R) = cv2.split(image)# Show each channel individuallycv2.imshow(&quot;Red&quot;,R)cv2.imshow(&quot;Green&quot;,G)cv2.imshow(&quot;Blue&quot;,B)cv2.waitKey(0)# Merge the image back together againmerged = cv2.merge([B,G,R])cv2.imshow(&quot;Merged&quot;,merged)cv2.waitKey(0)cv2.destroyAllWindows()</code></pre><p>通常，我们会想到RGB颜色空间中的图像——首先是红色，第二个是绿色，第三个是蓝色。但是，OpenCV以反向通道顺序将RGB图像存储为NumPy阵列。 它不是以RGB顺序存储图像，而是以BGR顺序存储图像; 因此我们以相反的顺序解包元组。然后将每个通道的图像显示出来。最后我们再将各个通道的图像合并成原图。</p><p>显示图像：</p><p><img src="https://i.imgur.com/cLscQGR.png" alt=""></p><p>红色通道非常暗。这是有道理的，因为海洋场景中的红色很少。存在的红色要么非常暗，要么没有代表，要么非常light，并且可能是波浪崩溃时白色泡沫的一部分。</p><p>绿色通道在图像中更具代表性，因为海水确实包含绿色色调。</p><p>最后，蓝色通道非常light，在某些位置接近纯白色。这是因为我们的图像中大量呈现蓝色阴影。</p><pre><code># Now, let&apos;s visualize each channel in colorzeros = np.zeros(image.shape[:2],dtype=&quot;uint8&quot;)cv2.imshow(&quot;Red&quot;,cv2.merge([zeros,zeros,R]))cv2.imshow(&quot;Green&quot;,cv2.merge([zeros,G,zeros]))cv2.imshow(&quot;Blue&quot;,cv2.merge([B,zeros,zeros]))cv2.waitKey(0)</code></pre><p>显示效果：</p><p><img src="https://i.imgur.com/KJ2y1Wi.png" alt=""></p><p>上面代码可以看到另一种可视化图像通道的方法。为了显示通道的实际“颜色”，我们首先需要使用cv2.split拆分图像。然后，我们需要重新构建图像，但这次设置所有像素，但当前通道为零。</p><p>我们首先构造了一个零的NumPy数组，其宽度和高度与原始图像相同。然后，为了构造图像的红色通道表示，我们调用cv2.merge，但为绿色和蓝色通道指定我们的零数组。后面采取类似的方法。</p><p><strong>用到的函数</strong></p><p><span id="inline-blue">cv2.split</span></p><p><span id="inline-blue">cv2.merge</span></p><p><span id="inline-blue">cv2.destroyAllWindows</span></p><h3 id="更多的参考："><a href="#更多的参考：" class="headerlink" title="更多的参考："></a>更多的参考：</h3><p><a href="https://ppao.pyimagesearch.com/lessons/ppao-chapter-6-image-processing/" target="_blank" rel="noopener">PPaO Chapter 6 – Image Processing</a></p><hr>]]></content>
    
    <summary type="html">
    
      第八个代码
    
    </summary>
    
      <category term="计算机视觉" scheme="https://0Leo0.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="Opencv" scheme="https://0Leo0.github.io/tags/Opencv/"/>
    
  </entry>
  
  <entry>
    <title>OpenCV_python3_07</title>
    <link href="https://0Leo0.github.io//2018/OpenCV_python3_07.html"/>
    <id>https://0Leo0.github.io//2018/OpenCV_python3_07.html</id>
    <published>2018-11-21T12:17:50.000Z</published>
    <updated>2018-11-21T13:13:22.600Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><a id="more"></a><h2 id="Practical-Python-and-OpenCV-3rd-Edition-07"><a href="#Practical-Python-and-OpenCV-3rd-Edition-07" class="headerlink" title="Practical Python and OpenCV,3rd Edition 07"></a>Practical Python and OpenCV,3rd Edition 07</h2><hr><h3 id="MASKING"><a href="#MASKING" class="headerlink" title="MASKING"></a>MASKING</h3><p>接下来我们看一下masking technique。</p><p>使用mask可以让我们只关注我们感兴趣的图像部分。</p><p>例如，假设我们正在建立一个识别面部的计算机视觉系统。我们有兴趣查找和描述的图像的唯一部分是包含面部的图像部分——我们根本不关心图像的其余内容。如果我们可以在图像中找到面部，我们可以构造一个mask来仅显示图像中的面部。</p><p>新建一个masking.py</p><pre><code># Import the necessary packagesimport numpy as npimport argparseimport cv2# Construct the argument parser and parse the argumentsap = argparse.ArgumentParser()ap.add_argument(&quot;-i&quot;, &quot;--image&quot;, required = True,    help = &quot;Path to the image&quot;)args = vars(ap.parse_args())# Load the image and show itimage = cv2.imread(args[&quot;image&quot;])cv2.imshow(&quot;Original&quot;, image)</code></pre><p>上面读取并显示原始图片，接下来我们构造一个NumPy数组，填充零，与我们的图像具有相同的宽度和高度。为了绘制白色矩形，我们首先通过划分宽度和高度来计算图像的中心，使用//运算符表示整数除法。最后，我们使用cv2.rectangle函数画出白色矩形。</p><pre><code># Masking allows us to focus only on parts of an image that# interest us. A mask is the same size as our image, but has# only two pixel values, 0 and 255. Pixels with a value of 0# are ignored in the orignal image, and mask pixels with a# value of 255 are allowed to be kept. For example, let&apos;s# construct a mask with a 150x150 square at the center of it# and mask our image.mask = np.zeros(image.shape[:2], dtype = &quot;uint8&quot;)(cX, cY) = (image.shape[1] // 2, image.shape[0] // 2)cv2.rectangle(mask, (cX - 75, cY - 75), (cX + 75 , cY + 75), 255, -1)cv2.imshow(&quot;Mask&quot;, mask)</code></pre><p>我们使用cv2.bitwise_and函数应用我们的mask。前两个参数是图像本身。显然，对于图像中的所有像素，AND功能将为True。但是，此函数的重要部分是mask关键字参数。通过提供mask，cv2.bitwise_and函数仅检查mask中“on”的像素。在这种情况下，只有矩形白色区域是显示出来的。</p><pre><code># Apply out mask -- notice how only the center rectangular# region of the pill is shownmasked = cv2.bitwise_and(image, image, mask = mask)cv2.imshow(&quot;Mask Applied to Image&quot;, masked)cv2.waitKey(0)</code></pre><p>接下来，我们重新初始化我们的蒙版，用零填充与图像相同的尺寸。然后，我们在mask image上绘制一个白色圆圈，从图像的中心开始，半径为100像素。然后再次使用cv2.bitwise_and函数应用圆形mask。</p><pre><code># Now, let&apos;s make a circular mask with a radius of 100 pixelsmask = np.zeros(image.shape[:2],dtype=&quot;uint8&quot;)cv2.circle(mask,(cX,cY),100,255,-1)masked = cv2.bitwise_and(image,image,mask=mask)cv2.imshow(&quot;Mask&quot;,mask)cv2.imshow(&quot;Mask Applied to Image&quot;,masked)cv2.waitKey(0)</code></pre><p>显示效果：</p><p><img src="https://i.imgur.com/UHw8Qzh.png" alt=""></p><p><img src="https://i.imgur.com/cQwpOEx.png" alt=""></p><p><strong>用到的函数</strong></p><p><span id="inline-blue">cv2.bitwise_and</span></p><p><span id="inline-blue">cv2.ractangle</span></p><p><span id="inline-blue">cv2.circle</span></p><h3 id="更多的参考："><a href="#更多的参考：" class="headerlink" title="更多的参考："></a>更多的参考：</h3><p><a href="https://ppao.pyimagesearch.com/lessons/ppao-chapter-6-image-processing/" target="_blank" rel="noopener">PPaO Chapter 6 – Image Processing</a></p><hr>]]></content>
    
    <summary type="html">
    
      第七个代码
    
    </summary>
    
      <category term="计算机视觉" scheme="https://0Leo0.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="Opencv" scheme="https://0Leo0.github.io/tags/Opencv/"/>
    
  </entry>
  
  <entry>
    <title>OpenCV_python3_06</title>
    <link href="https://0Leo0.github.io//2018/OpenCV_python3_06.html"/>
    <id>https://0Leo0.github.io//2018/OpenCV_python3_06.html</id>
    <published>2018-11-21T04:17:50.000Z</published>
    <updated>2018-11-21T12:45:07.130Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><a id="more"></a><h2 id="Practical-Python-and-OpenCV-3rd-Edition-06"><a href="#Practical-Python-and-OpenCV-3rd-Edition-06" class="headerlink" title="Practical Python and OpenCV,3rd Edition 06"></a>Practical Python and OpenCV,3rd Edition 06</h2><hr><h3 id="按位运算-bitwise-operations"><a href="#按位运算-bitwise-operations" class="headerlink" title="按位运算(bitwise operations)"></a>按位运算(bitwise operations)</h3><p>现在我们将检查四个按位运算：AND，OR，XOR和NOT。 这四个操作虽然非常基础和低级，但对图像处理至关重要。</p><p>新建一个bitwise.py</p><pre><code>import numpy as np import cv2 rectangle = np.zeros((300,300),dtype=&quot;uint8&quot;)cv2.rectangle(rectangle,(25,25),(275,275),255,-1)cv2.imshow(&quot;Rectangle&quot;,rectangle)circle = np.zeros((300,300),dtype=&quot;uint8&quot;)cv2.circle(circle,(150,150),150,255,-1)cv2.imshow(&quot;Circle&quot;,circle)cv2.waitKey(0)</code></pre><p><strong>解释</strong>：</p><p>我们将矩形图像初始化为0×300NumPy数组。然后在图像的中心绘制一个250×250的白色矩形(实心)。类似地，我们初始化另一个图像以包含我们的圆，再次以图像的中心为中心，半径为150像素。</p><p>显示效果：</p><p><img src="https://i.imgur.com/CN8IzrL.png" alt=""></p><pre><code>bitwiseAnd = cv2.bitwise_and(rectangle,circle)cv2.imshow(&quot;AND&quot;,bitwiseAnd)    cv2.waitKey(0)bitwiseOr = cv2.bitwise_or(rectangle,circle)cv2.imshow(&quot;OR&quot;,bitwiseOr)cv2.waitKey(0)bitwiseXor = cv2.bitwise_xor(rectangle,circle)cv2.imshow(&quot;XOR&quot;,bitwiseXor)cv2.waitKey(0)bitwiseNot = cv2.bitwise_not(circle)cv2.imshow(&quot;NOT&quot;,bitwiseNot)cv2.waitKey(0)</code></pre><p>如上所述，一个像素 is turned “on” 如果它有一个大于0的值，否则是”turned off”,如果它有一个0值。Bitwise函数在这些二进制条件下运行。</p><p>为了利用按位函数，我们假设(在大多数情况下)我们正在比较两个像素（唯一的例外是NOT函数)。我们将比较每个像素，然后构造我们的按位表示。</p><ol><li>AND:当且仅当两个像素都大于零时，按位AND为真</li><li>OR:如果两个像素中的任何一个大于零，则按位OR为真。</li><li>XOR:异或，取异，也就是两个不一样时才为真</li><li>NOT:按位NOT反转图像中的“开”和“关”像素。</li></ol><p>首先，我们使用cv2.bitwise_and函数对我们的矩形和圆形图像应用按位AND。如上面的列表所示，当且仅当两个像素都大于零时，按位AND才为真。 我们按位AND的输出可以如下图所示。我们可以看到正方形的边缘丢失了，因为我们的矩形不会覆盖像圆圈那样大的区域，因此两个像素都不会“打开”。</p><p>显示效果:</p><p><img src="https://i.imgur.com/rTDnk2J.png" alt=""></p><p>然后，我们使用按位OR，bitwise_or函数。 如果两个像素中的任何一个大于零，则按位OR为真。下图显示了按位OR的输出。在这种情况下，我们的正方形和矩形已合并在一起。</p><p>显示效果：</p><p><img src="https://i.imgur.com/BaQ4Apj.png" alt=""></p><p>接下来是按位XOR函数，使用cv2.bitwise_xor函数。取两个图形不一样的地方为真。其余为假，就是0，黑色。</p><p>显示效果：</p><p><img src="https://i.imgur.com/KdCWjwV.png" alt=""></p><p>最后，我们使用cv2.bitwise_not函数应用NOT函数。实质上，按位NOT函数会翻转像素值。所有大于零的像素都设置为零，所有设置为零的像素都设置为255.下图为我们的白色圆圈翻转为黑色圆圈。</p><p>显示效果：</p><p><img src="https://i.imgur.com/a0mnRFR.png" alt=""></p><p><strong>用到的函数</strong></p><p><span id="inline-blue">cv2.bitwise_and</span></p><p><span id="inline-blue">cv2.bitwise_or</span></p><p><span id="inline-blue">cv2.bitwise_xor</span></p><p><span id="inline-blue">cv2.bitwise_not</span></p><h3 id="更多的参考："><a href="#更多的参考：" class="headerlink" title="更多的参考："></a>更多的参考：</h3><p><a href="https://ppao.pyimagesearch.com/lessons/ppao-chapter-6-image-processing/" target="_blank" rel="noopener">PPaO Chapter 6 – Image Processing</a></p><hr>]]></content>
    
    <summary type="html">
    
      第六个代码
    
    </summary>
    
      <category term="计算机视觉" scheme="https://0Leo0.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="Opencv" scheme="https://0Leo0.github.io/tags/Opencv/"/>
    
  </entry>
  
  <entry>
    <title>OpenCV_python3_05</title>
    <link href="https://0Leo0.github.io//2018/OpenCV_python3_05.html"/>
    <id>https://0Leo0.github.io//2018/OpenCV_python3_05.html</id>
    <published>2018-11-20T04:17:50.000Z</published>
    <updated>2018-11-21T10:17:52.733Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><a id="more"></a><h2 id="Practical-Python-and-OpenCV-3rd-Edition-05"><a href="#Practical-Python-and-OpenCV-3rd-Edition-05" class="headerlink" title="Practical Python and OpenCV,3rd Edition 05"></a>Practical Python and OpenCV,3rd Edition 05</h2><hr><h3 id="图像算术-image-arithmetic"><a href="#图像算术-image-arithmetic" class="headerlink" title="图像算术(image arithmetic)"></a>图像算术(image arithmetic)</h3><p>我们都知道基本的算术运算，如加法和减法。但是在处理图像时，我们需要记住颜色空间和数据类型的限制。</p><p>例如，RGB图像具有落在[0,255]范围内的像素。那么如果我们正在检查强度为250的像素并尝试向它添加10，会发生什么？</p><p>在正常的算术规则下，我们最终得到的值为260.但是，由于RGB图像表示为8位无符号整数，因此260不是有效值。</p><p>那么，会发生什么？我们是否应该执行某种检查以确保没有像素落在[0,255]范围之外，从而将所有像素剪切为最小值0和最大值255？</p><p>或者我们应用模数运算，并“wrap around(环绕)”？在模数规则下，添加10到250将简单地回绕到值4。</p><p>哪种方式是处理超出[0,255]范围的图像添加和减法的“正确”方法？</p><p>答案是没有正确的方法——它只取决于你如何操纵像素以及你想要的结果。</p><p>但是，请务必记住OpenCV和NumPy加法之间存在差异。NumPy将执行模运算和“warp around”。另一方面，OpenCV将执行裁剪并确保像素值永远不会超出范围[0,255]</p><p>请看代码：</p><pre><code>from __future__ import print_functionimport numpy as np import argparse import cv2 ap = argparse.ArgumentParser()ap.add_argument(&apos;-i&apos;,&quot;--image&quot;,required=True,        help=&quot;path to the image&quot;)args = vars(ap.parse_args())image = cv2.imread(args[&quot;image&quot;])cv2.imshow(&quot;Original&quot;,image)print(&quot;max of 255: {}&quot;.format(cv2.add(np.uint8([200]),np.uint8([100]))))print(&quot;min of 0: {}&quot;.format(cv2.add(np.uint8([50]),np.uint8([100]))))print(&quot;wrap around: {}&quot;.format(np.uint8([200]) + np.uint8([100])))print(&quot;wrap around: {}&quot;.format(np.uint8([50]) - np.uint8([100])))</code></pre><p><strong>解释</strong>：</p><p>第一个print函数，我们定义了两个8位无符号整数的NumPy数组。第一个数组有一个元素：值为200.第二个数组也只有一个元素，但值为100.然后我们使用OpenCV的cv2.add方法将值一起添加。那么返回的值到底回事多少呢？那么，根据标准算术规则，我们认为结果应该是300，但是，请记住，我们正在使用8位无符号整数，其范围仅在[0,255]之间。由于我们使用的是cv2.add方法，OpenCV会为我们处理剪切，并确保添加产生的最大值为255.当我们执行此代码时，我们可以看到返回值是255。</p><p>第二个print函数，我们使用cv2.subtract执行减法。同样，我们定义了两个NumPy数组，每个数组都有一个元素，以及8位无符号整数数据类型。第一个数组的值为50，第二个数组的值为100。根据算术规则，返回值本该是-50，但是OpenCV再一次为我们进行裁剪，返回值会是0.</p><p>max of 255: [[255]]</p><p>min of 0: [[0]]</p><p>但是如果我们使用NumPy来执行算术而不是OpenCV会发生什么？</p><p>第三个print函数，首先，我们定义两个NumPy数组，每个数组都有一个元素，以及8位无符号整数数据类型。 第一个数组的值为200，第二个数组的值为100.使用cv2.add函数，我们的添加将被剪切并返回值255。但是Numpy并不会执行裁剪。它会执行模运算并”warps around(环绕)”。一旦值达到255，Numpy将回绕到0并再一次向上技术，直到100 steps reached。</p><p>第四个print函数，在减法期间一旦达到0，模运算操作就会回绕并从255开始向后计数。</p><p>wrap around: [44]</p><p>wrap around: [206]</p><p>现在我们已经在OpenCV和NumPy中探讨了图像算法的注意事项，让我们对实际图像执行算法并查看结果：</p><pre><code>M = np.ones(image.shape,dtype=&quot;uint8&quot;) * 100added = cv2.add(image,M)cv2.imshow(&quot;Added&quot;,added)M = np.ones(image.shape,dtype=&quot;uint8&quot;) * 50 subtracted = cv2.subtract(image,M)cv2.imshow(&quot;Subtracted&quot;,subtracted)cv2.waitKey(0)</code></pre><p>显示效果:</p><p><img src="https://i.imgur.com/SKd6AO8.png" alt=""></p><p><strong>解释</strong>：</p><p>我们首先定义了一个NumPy数组，其大小与我们的图像相同 同样，我们肯定使用8位无符号整数作为我们的数据类型。为了用100的值而不是1来填充我们的矩阵，我们简单地将1的矩阵乘以100.最后，我们使用cv2.add函数将我们的100的矩阵添加到原始图像——从而增加每个像素强度 图像乘以100，但如果它们试图超过255，则确保所有值都被剪切到范围[0,255]。</p><p>同样的，我们再定义了一个NumPy数组，并将原始图像减去50个像素，最后，曾经是白色的像素现在看起来是灰色的。这是因为我们从像素中减去50并将它们推向RGB颜色空间的较暗区域。</p><p><strong>用到的函数</strong></p><p><span id="inline-blue">cv2.add</span></p><p><span id="inline-blue">cv2.subtract</span></p><h3 id="更多的参考："><a href="#更多的参考：" class="headerlink" title="更多的参考："></a>更多的参考：</h3><p><a href="https://ppao.pyimagesearch.com/lessons/ppao-chapter-6-image-processing/" target="_blank" rel="noopener">PPaO Chapter 6 – Image Processing</a></p><hr>]]></content>
    
    <summary type="html">
    
      第五个代码
    
    </summary>
    
      <category term="计算机视觉" scheme="https://0Leo0.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="Opencv" scheme="https://0Leo0.github.io/tags/Opencv/"/>
    
  </entry>
  
  <entry>
    <title>OpenCV_python3_04</title>
    <link href="https://0Leo0.github.io//2018/OpenCV_python3_04.html"/>
    <id>https://0Leo0.github.io//2018/OpenCV_python3_04.html</id>
    <published>2018-11-16T14:17:50.000Z</published>
    <updated>2018-11-22T06:55:34.070Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><a id="more"></a><h2 id="Practical-Python-and-OpenCV-3rd-Edition-04"><a href="#Practical-Python-and-OpenCV-3rd-Edition-04" class="headerlink" title="Practical Python and OpenCV,3rd Edition 04"></a>Practical Python and OpenCV,3rd Edition 04</h2><hr><h3 id="图像转换-image-transformations"><a href="#图像转换-image-transformations" class="headerlink" title="图像转换(image transformations)"></a>图像转换(image transformations)</h3><p>本节中，我们将介绍基本的图像转换。 这些是您可能应用于图像的常用技术，包括平移，旋转，调整大小，翻转和裁剪。</p><h4 id="平移-Translation"><a href="#平移-Translation" class="headerlink" title="平移(Translation)"></a>平移(Translation)</h4><p>我们首先介绍的是Translation。Trans Latino是沿x和y轴移动图像。 使用Translation，我们可以向上，向下，向左或向右移动图像，以及上述任意组合！请看下面的代码(translation.py)：</p><pre><code>import numpy as np import argparse import imutils import cv2 ap = argparse.ArgumentParser()ap.add_argument(&apos;-i&apos;,&quot;--image&quot;,required=True,    help=&quot;path to the image&quot;)args = vars(ap.parse_args())image = cv2.imread(args[&quot;image&quot;])cv2.imshow(&quot;Original&quot;,image)M = np.float32([[1,0,25],[0,1,50]])shifted = cv2.warpAffine(image,M,(image.shape[1],image.shape[0]))cv2.imshow(&quot;Shifted Down and Right&quot;,shifted)M = np.float32([[1,0,-50],[0,1,-90]])shifted = cv2.warpAffine(image,M,(image.shape[1],image.shape[0]))cv2.imshow(&quot;Shifted Up and Left&quot;,shifted)</code></pre><p><strong>解释</strong>:</p><p>主要从M——我们的的translation matrix讲起，该矩阵告诉我们的图像要进行平移多少像素(从左到右，从上到下)。该矩阵被定义为float32类型的数组，因为OpenCV希望该矩阵是一个float类型。The first row of the matrix is [1,0,t<sub>x</sub>]，其中t<sub>x</sub>是the number of pixels we will shift the image left or right，而负值则表示图像将向左平移，正值表示图像将向右平移。然后我们定义the second row of the matrix as [0,1,t<sub>y</sub>]，其中，t<sub>y</sub>是the number of pixels we will shift the image up or down。其中，负值表示图像向上平移，正值表示图像向下平移。</p><p>使用了上面的那个标记，我们看代码中，将t<sub>x</sub>=25,t<sub>y</sub>=50则意味着，我们将图像向右平移25个像素，向下平移50个像素。</p><p>我们定义好了平移矩阵之后，图像的实际平移是使用了<code>cv2.warpAffine</code>函数来执行，该函数的第一个参数是我们要进行平移的图像，第二个参数是我们的平移矩阵M，最后我们需要手动地提供图像的尺寸(width and height)作为第三个参数。</p><p>前面实现了图像的平移，但是代码太过冗余，我们新建一个<code>.py</code>文件来实现平移功能(imutils.py)</p><pre><code>import numpy as np import cv2 def translate(image,x,y):    M = np.float32([[1,0,x],[0,1,y]])    shifted = cv2.warpAffine(image,M,(image.shape[1],image.shape[0]))    return shifted</code></pre><p><strong>解释</strong>:</p><p>我们的平移方法有三个参数：我们要平移的图像，我们沿x轴移动的像素数，以及我们将沿y轴移动的像素数。然后，此方法定义我们的平移矩阵M，然后再应用实际移位。最后，我们返回移位后的图像。</p><p>修改translation.py的内容</p><pre><code>shifted = imutils.translate(image,0,100)cv2.imshow(&quot;Shifted Down&quot;,shifted)cv2.waitKey(0)</code></pre><p>运行结果：</p><p><img src="https://i.imgur.com/174QVuy.png" alt=""></p><h4 id="旋转-Rotation"><a href="#旋转-Rotation" class="headerlink" title="旋转(Rotation)"></a>旋转(Rotation)</h4><p>在这里，我们将使用θ来表示要旋转多少度。</p><p>rotate.py</p><pre><code>import numpy as np import argparse import imutilsimport cv2ap = argparse.ArgumentParser()ap.add_argument(&apos;-i&apos;,&quot;--image&quot;,required=True,    help=&quot;Path to the image&quot;)args = vars(ap.parse_args())image = cv2.imread(args[&quot;image&quot;])cv2.imshow(&quot;Original&quot;,image)(h,w) = image.shape[:2]center = (w // 2, h // 2)M = cv2.getRotationMatrix2D(center,45,1.0)rotated = cv2.warpAffine(image,M,(w,h))cv2.imshow(&quot;Rotated by 45 Degrees&quot;,rotated)M = cv2.getRotationMatrix2D(center,-90,1.0)rotated = cv2.warpAffine(image,M,(w,h))cv2.imshow(&quot;Rotated by -90 Degrees&quot;,rotated)</code></pre><p><strong>解释</strong>:</p><p>前面还是导入必要的包以及解析输入参数和显示原始图像。</p><p>当我们旋转图像时，我们需要指定我们想要旋转的点。 在大多数情况下，您需要围绕图像的中心旋转; 我们首先获取图像的宽度和高度，因为OpenCV将图像读取为一个numpy数组，所以和矩阵类似，矩阵的行对应着高，也就是<code>height=image.shape[0]</code>，矩阵的列对应着图像的宽，也就是<code>width=image.shape[1]</code>，然后我们除以2，确定图像的中心位置。这里我们使用和C语言一样的除法，//表示整除法，以确保我们得到的是整数。</p><p>就像我们定义一个矩阵来平移图像一样，我们也定义了一个矩阵来旋转图像。 不是使用NumPy手动构造矩阵，而是调用<code>cv2.getRotationMatrix2D</code>方法。</p><p><code>cv2.getRotationMatrix2D</code>函数有三个参数：第一个是我们想要旋转图像的点，在这里是图像的中心位置，然后我们指定需要旋转的角度θ，我们第一次是旋转了45度，最后一个参数图像的比例。我们还没有讨论调整图像的大小，但是在这里你可以指定浮点值，其中1.0表示使用相同的图像尺寸。 但是，如果指定值为2.0，则图像的大小将加倍。 类似地，值0.5将图像的大小减半。</p><p>一旦我们从<code>cv2.getRotationMatrix2D</code>函数获得旋转矩阵M，我们就可以使用<code>cv2.warpAffine</code>方法将旋转应用于我们的图像。此函数的第一个参数是我们想要旋转的图像。然后，我们指定旋转矩阵M以及图像的输出尺寸（宽度和高度）。然后，显示旋转了的图像。</p><p>显示效果为：</p><p><img src="https://i.imgur.com/iseOU2P.png" alt=""></p><p>接下来为了让代码更加的pretty and Pythonic，我们在imutils.py中添加一个rotate方法</p><pre><code>def rotate(image,angle,center=None,scale=1.0):    (h,w) = image.shape[:2]    if center is None:        center = (w // 2 , h // 2)    M = cv2.getRotationMatrix2D(center,angle,scale)    rotated = cv2.warpAffine(image,M,(w,h))    return rotated</code></pre><p><strong>解释</strong>：</p><p>我们的rotate方法有四个参数。第一个是你的image。第二个是我们想要旋转图像的角度θ。我们提供两个可选的关键字参数，center和scale。center参数是我们希望旋转图像的点。如果提供了值None，则该方法自动选图像中心为旋转点。最后，scale参数用于处理在旋转期间是否应更改图像的大小。scale参数的默认值为1.0，这意味着不应调整大小。</p><p>再次修改rotate.py文件，</p><pre><code>rotated = imutils.rotate(image,180)cv2.imshow(&quot;Rotated by 180 Degrees&quot;,rotated)cv2.waitKey(0)</code></pre><p>运行结果：</p><p><img src="https://i.imgur.com/WqibdLD.png" alt=""></p><p>确实很pythonic！！！</p><h4 id="Resizing"><a href="#Resizing" class="headerlink" title="Resizing"></a>Resizing</h4><pre><code>import numpy as np import argparseimport imutilsimport cv2 ap = argparse.ArgumentParser()ap.add_argument(&apos;-i&apos;,&quot;--image&quot;,required=True,help=&quot;Path to the image&quot;)args = vars(ap.parse_args())image = cv2.imread(args[&quot;image&quot;])cv2.imshow(&quot;Original&quot;,image)</code></pre><p><strong>解释</strong>：</p><p>这个和前面一样，解析参数，读取图片并显示图片</p><pre><code>r = 150.0 / image.shape[1]dim = (150,int(image.shape[0] * r))resized = cv2.resize(image,dim,interpolation=cv2.INTER_AREA)cv2.imshow(&quot;Resized (Width)&quot;,resized)</code></pre><p><strong>解释</strong>：</p><p><code>r</code>表示<code>the aspect ratio</code>。这里<code>image.shape[1]</code>表示我们图片的宽度，上面的代码我们设置我们图片的新宽度为150个pixels，为了计算新高度与旧高度的比率，我们简单地将比率r定义为新宽度（150像素）除以旧宽度，接着为了保持宽高比，我们计算出高度(height)的变化为 <code>height / width * 150</code>。接下来调用resize函数，该函数的第一个参数是我们希望调整大小的图像，第二个参数是我们为新图像计算的尺寸。最后一个参数是我们的插值方法，这是在背后工作的算法 处理实际图像的大小调整方式。一般来说，我发现使用cv2.INTER_AREA在调整大小时获得最佳效果; 但是，其他适当的选择包括cv2.INTER_LINEAR，cv2.INTER_CUBIC和cv2.INTER_NEAREST。</p><pre><code>r = 50.0 / image.shape[0]dim = (int(image.shape[1] * r),50)resized = cv2.resize(image,dim,interpolation=cv2.INTER_AREA)cv2.imshow(&quot;Resized (Height)&quot;,resized)cv2.waitKey(0)</code></pre><p><strong>解释</strong>：</p><p>这一段代码和前一段类似，只不过这一次是固定高度为50个像素，然后保持宽高比计算出宽度，显示图像。</p><pre><code>resized = imutils.resize(image,width = 100)cv2.imshow(&quot;Resized via Function&quot;,resized)cv2.waitKey(0)</code></pre><p><strong>解释</strong>：</p><p>前面都是用了三行代码实现图像的resize，我们可以利用<code>imutils.resize</code>函数只需要一行即可实现一样的功能。</p><p>在<code>imutils.py</code>函数中实现：</p><pre><code>def resize(image,width=None,height=None,inter=cv2.INTER_AREA):    dim = None     (h,w) = image.shape[:2]    if width is None and height is None:        return image     if width is None:        r = height / float(h)        dim = (int(w * r),height)    else:        r = width / float(w)        dim = (width,int(h * r))    resized = cv2.resize(image,dim,interpolation=inter)    return resized</code></pre><p><strong>解释</strong>：</p><p> 第一个参数是我们想要调整大小的图像。然后，我们定义两个关键字参数，宽度和高度。这两个参数都不能为None，否则我们将不知道如何调整图像大小。我们还提供inter，这是我们的插值方法，默认为cv2.INTER_AREA。</p><p>显示效果：</p><p><img src="https://i.imgur.com/wmyegIu.png" alt=""></p><h4 id="Flipping"><a href="#Flipping" class="headerlink" title="Flipping"></a>Flipping</h4><p>接下来我们要探索的图像转换是翻转图像。 我们可以围绕x或者翻转图像y轴，甚至两者。查看下图理解一下水平和垂直翻转的区别。</p><p><img src="https://i.imgur.com/5hkYcNH.png" alt=""></p><pre><code>import argparseimport cv2ap = argparse.ArgumentParser()ap.add_argument(&apos;-i&apos;,&quot;--image&quot;,required=True,    help=&quot;Path to the image&quot;)args = vars(ap.parse_args())image = cv2.imread(args[&quot;image&quot;])cv2.imshow(&quot;Original&quot;,image)</code></pre><p><strong>解释</strong>：<br>和前面一样，解析参数，显示原始图片</p><pre><code>flipped = cv2.flip(image,1)cv2.imshow(&quot;Flipped Horizontally&quot;,flipped)flipped = cv2.flip(image,0)cv2.imshow(&quot;Flipped Vertically&quot;,flipped)flipped = cv2.flip(image,-1)cv2.imshow(&quot;Flipped Horizontally &amp; Vertically&quot;,flipped)cv2.waitKey(0)</code></pre><p>我们通过调用cv2.flip函数来完成图像的翻转。cv2.flip方法需要两个参数：我们要翻转的图像和a flip code，用于确定我们如何翻转图片。</p><p>使用翻转代码值1表示我们将围绕y轴水平翻转图像。指定翻转代码为0表示我们想要围绕x轴垂直翻转图像。最后，使用负翻转代码翻转两个轴图像。</p><p>显示效果：</p><p><img src="https://i.imgur.com/ghs5Ha6.png" alt=""></p><h4 id="Cropping"><a href="#Cropping" class="headerlink" title="Cropping"></a>Cropping</h4><p>当我们裁剪图像时，我们想要删除我们不感兴趣的图像的外部部分。我们可以使用NumPy数组切片来完成图像裁剪。</p><pre><code>import numpy as np import argparseimport cv2 ap = argparse.ArgumentParser()ap.add_argument(&apos;-i&apos;,&quot;--image&quot;,required=True,    help=&quot;Path to the image&quot;)args = vars(ap.parse_args())image = cv2.imread(args[&quot;image&quot;])cv2.imshow(&quot;Original&quot;,image)cropped = image[30:120,240:335]cv2.imshow(&quot;T-Rex Face&quot;,cropped)cv2.waitKey(0)</code></pre><p><strong>解释</strong>：</p><p>实际裁剪在一行代码上进行。我们提供NumPy数组切片以提取图像的矩形区域，从（240,30）开始到（335,120）结束。The order in which we supply the<br>indexes to the crop may seem counterintuitive(有悖常理); 但请记住，OpenCV将图像表示为NumPy数组，其高度优先，宽度为次之。这意味着我们需要在x轴之前提供y轴值.</p><p>为了执行我们的裁剪，NumPy需要四个索引：</p><ol><li><p>开始y：起始y坐标。在这种情况下，我们从y=30开始。</p></li><li><p>结束y：结束y坐标。我们将在y=120时结束我们的裁剪。</p></li><li><p>开始x：切片的起始x坐标。我们在x=240时开始裁剪</p></li><li><p>结束x：切片的结束x轴坐标。我们的切片在x=335处结束</p></li></ol><p>显示效果:</p><p><img src="https://i.imgur.com/HkU9bOf.png" alt=""></p><p><strong>用到的函数</strong></p><p><span id="inline-blue">cv2.warpAffine</span></p><p><span id="inline-blue">cv2.getRotationMatrix2D</span></p><p><span id="inline-blue">cv2.resize</span></p><p><span id="inline-blue">cv2.flip</span></p><h3 id="更多的参考："><a href="#更多的参考：" class="headerlink" title="更多的参考："></a>更多的参考：</h3><p><a href="https://ppao.pyimagesearch.com/lessons/ppao-chapter-5-drawing/" target="_blank" rel="noopener">chapter-5-drawing</a></p><hr>]]></content>
    
    <summary type="html">
    
      第四个代码
    
    </summary>
    
      <category term="计算机视觉" scheme="https://0Leo0.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="Opencv" scheme="https://0Leo0.github.io/tags/Opencv/"/>
    
  </entry>
  
  <entry>
    <title>OpenCV_python3_03</title>
    <link href="https://0Leo0.github.io//2018/OpenCV_python3_03.html"/>
    <id>https://0Leo0.github.io//2018/OpenCV_python3_03.html</id>
    <published>2018-11-09T07:17:57.000Z</published>
    <updated>2018-11-09T09:18:55.409Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><a id="more"></a><h2 id="Practical-Python-and-OpenCV-3rd-Edition-03"><a href="#Practical-Python-and-OpenCV-3rd-Edition-03" class="headerlink" title="Practical Python and OpenCV,3rd Edition 03"></a>Practical Python and OpenCV,3rd Edition 03</h2><hr><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><pre><code>import numpy as np import cv2 canvas = np.zeros((300,300,3),dtype=&quot;uint8&quot;)</code></pre><p><strong>解释</strong>:</p><p>前两个是导入python库，接着就构造一个Numpy数组，使用<code>.zeros</code>方法初始化一个300 rows 和 300 columns的矩阵(也就是说画布的大小为300x300=90000个像素大小)，同时还分配了3个channels，one for Red,Green,and Blue,respectively。同时需要注意的是数据类型，dtype。由于我们将图像表示为像素在[0,255]范围内的RGB图像，因此我们使用8位无符号整数或uint8。</p><pre><code>green = (0,255,0)cv2.line(canvas,(0,0),(300,300),green)cv2.imshow(&quot;Canvas&quot;,canvas)cv2.waitKey(0)red = (0,0,255)cv2.line(canvas,(300,0),(0,300),red,3)cv2.imshow(&quot;Canvas&quot;,canvas)cv2.waitKey(0)</code></pre><p><strong>解释</strong>:</p><p>前面我们初始化了我们的画布，接下来我们开始画直线，首先我们定义了一个元组(tuple)来定义画笔的颜色,这里是绿色，然后我们调用<code>.line</code>方法，该方法的第一个参数是我们绘制的画布，第二个参数是该line的起点，我们设置开始点为(0,0)，我们还需要为该line提供一个结束点（第三个参数）。我们将结束点设置为（300,300)，最后一个参数是我们画笔的颜色，我们设置为绿色。接着将我们的图像显示出来，并且wait for a keypress.</p><p>第二段代码的<code>.line</code>方法的最后一个参数3就是我们画笔的thickness了，也就是画笔的厚度了。</p><p>显示效果为：</p><p><img src="https://i.imgur.com/UtO0byw.png" alt=""></p><pre><code>cv2.rectangle(canvas,(10,10),(60,60),green)cv2.imshow(&quot;Canvas&quot;,canvas)cv2.waitKey(0)cv2.rectangle(canvas,(50,200),(200,225),red,5)cv2.imshow(&quot;Canvas&quot;,canvas)cv2.waitKey(0)blue = (255,0,0)cv2.rectangle(canvas,(200,50),(225,125),blue,-1)cv2.imshow(&quot;Canvas&quot;,canvas)cv2.waitKey(0)</code></pre><p><strong>解释</strong>:</p><p>第一段代码我们使用了<code>.rectangle</code>方法，该方法的第一个参数是我们要画的画布，第二个参数是我们的rectangle的starting(x,y)位置，这里我们设置我们rectangle的开始point为(10,10)，然后我们还得设置我们矩形的结束点为(60,60),这个时候我们定义了一个(60-10,60-10)=(50,50)大小的像素区域。最后一个就是我们矩形的颜色了。第二段代码的第一行的最后一个参数是画笔的厚度，第三段代码的最后一个参数表示绘制一个solid(实心)的矩形。</p><p>显示效果为：</p><p><img src="https://i.imgur.com/GaNsOuD.png" alt=""></p><pre><code>canvas = np.zeros((300,300,3),dtype=&quot;uint8&quot;)(centerX,centerY) = (canvas.shape[1] // 2 , canvas.shape[0] // 2)white = (255,255,255)for r in range(0,175,25):    cv2.circle(canvas,(centerX,centerY),r,white)cv2.imshow(&quot;Canvas&quot;,canvas)cv2.waitKey(0)</code></pre><p><strong>解释</strong>:</p><p>我们首先初始化我们的画布，然后我们计算两个变量：centerX和centerY。这两个变量代表图像中心的(x,y)的坐标。我们首先获取图像的宽度(也就是列)，通过<code>.shape[1]</code>获取，然后获取图像的高度(也就是行)，通过<code>.shape[0]</code>获取，最后用//(取C语言的除法，不保留小数)除以2获取中心位置。获取了圆心的位置，接下来，用一个for循环，starting from 0 and ending at 150，每一次增加25的半径来画圆。<code>.circle</code>方法的第一个参数是我们的画布，然后我们将圆心坐标传给第二个参数，第三个参数是我们的半径大小r，最后一个是我们的圆的颜色。</p><p>显示效果为：</p><p><img src="https://i.imgur.com/y9UMENC.png" alt=""></p><pre><code>for i in range(0,25):    radius = np.random.randint(5, high = 200)    color = np.random.randint(0, high = 256 , size = (3,)).tolist()    pt = np.random.randint(0, high = 300, size=(2,))    cv2.circle(canvas,tuple(pt),radius,color,-1)cv2.imshow(&quot;Canvas&quot;,canvas)cv2.waitKey(0)</code></pre><p><strong>解释</strong>:</p><p>接下来我们画25个圆，用一个for循环来实现。首先是半径，我们使用Numpy的<code>.random.randint</code>方法生成[5,200)范围内的半径值，接着用该方法生成RGB颜色，范围是[0,255],为了得到三个随机的整数，而不是一个整数，我们传递关键字参数<code>size=(3,)</code>,数字3表示有3个数据，这样我们就获取了由3个值为[0,255]的随机数组成的元组来表示我们的RGB颜色了。接着哦我们需要一个圆心的point，我们也设置pt为[0,300)的值，但是圆心只需要两个数字，即(x,y)即可，因此，<code>size=(2,)</code>。最后我们调用<code>.circle</code>方法来画我们的圆。</p><p>显示效果为：</p><p><img src="https://i.imgur.com/TiBFOQs.png" alt=""></p><p>运行程序</p><p><img src="https://i.imgur.com/Yh6tdId.png" alt=""></p><p>点击图片部分，按键盘任意键结束脚本。</p><p><strong>完整的代码</strong></p><pre><code>import numpy as np import cv2 canvas = np.zeros((300,300,3),dtype=&quot;uint8&quot;)green = (0,255,0)cv2.line(canvas,(0,0),(300,300),green)cv2.imshow(&quot;Canvas&quot;,canvas)cv2.waitKey(0)red = (0,0,255)cv2.line(canvas,(300,0),(0,300),red,3)cv2.imshow(&quot;Canvas&quot;,canvas)cv2.waitKey(0)cv2.rectangle(canvas,(10,10),(60,60),green)cv2.imshow(&quot;Canvas&quot;,canvas)cv2.waitKey(0)cv2.rectangle(canvas,(50,200),(200,225),red,5)cv2.imshow(&quot;Canvas&quot;,canvas)cv2.waitKey(0)blue = (255,0,0)cv2.rectangle(canvas,(200,50),(225,125),blue,-1)cv2.imshow(&quot;Canvas&quot;,canvas)cv2.waitKey(0)canvas = np.zeros((300,300,3),dtype=&quot;uint8&quot;)(centerX,centerY) = (canvas.shape[1] // 2 , canvas.shape[0] // 2)white = (255,255,255)for r in range(0,175,25):    cv2.circle(canvas,(centerX,centerY),r,white)cv2.imshow(&quot;Canvas&quot;,canvas)cv2.waitKey(0)for i in range(0,25):    radius = np.random.randint(5, high = 200)    color = np.random.randint(0, high = 256 , size = (3,)).tolist()    pt = np.random.randint(0, high = 300, size=(2,))    cv2.circle(canvas,tuple(pt),radius,color,-1)cv2.imshow(&quot;Canvas&quot;,canvas)cv2.waitKey(0)    </code></pre><p><strong>用到的函数</strong></p><p><span id="inline-blue">cv2.line</span></p><p><span id="inline-blue">cv2.rectangle</span></p><p><span id="inline-blue">cv2.circle</span></p><h3 id="更多的参考："><a href="#更多的参考：" class="headerlink" title="更多的参考："></a>更多的参考：</h3><p><a href="https://ppao.pyimagesearch.com/lessons/ppao-chapter-5-drawing/" target="_blank" rel="noopener">chapter-5-drawing</a></p><p>名词：</p><p>Regions of Interest(ROIs)</p><p>machine-readable zones(MRZs)</p><h3 id="小测试："><a href="#小测试：" class="headerlink" title="小测试："></a>小测试：</h3><p>请实现下图效果，尽可能用少的代码。</p><p><img src="https://i.imgur.com/ZeLD60d.png" alt=""></p><p><a href="https://ppao.pyimagesearch.com/wp-content/uploads/2016/08/chapter5_quiz.py_.zip" target="_blank" rel="noopener">答案下载地址</a></p><hr>]]></content>
    
    <summary type="html">
    
      第三个代码
    
    </summary>
    
      <category term="计算机视觉" scheme="https://0Leo0.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="Oepncv" scheme="https://0Leo0.github.io/tags/Oepncv/"/>
    
  </entry>
  
  <entry>
    <title>OpenCV_python3_02</title>
    <link href="https://0Leo0.github.io//2018/OpenCV_python3_02.html"/>
    <id>https://0Leo0.github.io//2018/OpenCV_python3_02.html</id>
    <published>2018-11-09T03:17:57.000Z</published>
    <updated>2018-11-09T07:25:12.359Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><a id="more"></a><h2 id="Practical-Python-and-OpenCV-3rd-Edition-02"><a href="#Practical-Python-and-OpenCV-3rd-Edition-02" class="headerlink" title="Practical Python and OpenCV,3rd Edition 02"></a>Practical Python and OpenCV,3rd Edition 02</h2><hr><h3 id="基础说明"><a href="#基础说明" class="headerlink" title="基础说明"></a>基础说明</h3><h4 id="什么是像素"><a href="#什么是像素" class="headerlink" title="什么是像素"></a>什么是像素</h4><p>每个图像都由一组像素组成。 像素是图像的原始构建块。没有比像素更小的单位了。</p><p>通常，我们将像素视为出现在图像中给定位置的光的“颜色”或“强度”。</p><p>如果我们将图像视为网格，则网格中的每个方块都包含一个像素。</p><p>例如，假设我们有一个分辨率为500×300的图像。这意味着我们的图像表示为像素网格，有500行和300列。总体而言，我们的图像总共有 500×300 = 150,000像素。</p><p>大多数像素以两种方式表示：灰度(grayscale)和彩色(color)。在灰度图像中，每个像素具有0到255之间的值，其中0对应于“黑色”而255对应于“白色”。 0到255之间的值是不同的灰色阴影，其中，接近0的更加的darker，接近于255更加的lighter。</p><p>彩色通常以RGB颜色空间表示，one value for the Red component,one for Green,and one for Blue。</p><p>RGB中的每一种都由0到255范围内的整数表示，这表示颜色的“多少”。像素值只需要在[0,255]范围内，我们通常使用8位无符号整数来表示每种颜色强度。</p><p>然后，我们将这些值组合成图形中的RGB(红色，绿色，蓝色）元组(tuple)。 这个元组就代表我们的颜色。</p><p>为了构建一个白色，我们将完全填充每个红色，绿色和蓝色 buckets，如下所示:(255,255,255）。为了创建一个黑色，我们将每个bucket都清空：(0,0,0) ，为了创造一种纯红色，我们将完全填满红色的bucket：(255,0,0）。</p><h4 id="coordinate-system-坐标系统"><a href="#coordinate-system-坐标系统" class="headerlink" title="coordinate system(坐标系统)"></a>coordinate system(坐标系统)</h4><p>如上所述，图像表示为像素网格。 想象一下我们的网格作为一张方格纸。 使用该方格纸，点(0,0）对应于图像的左上角。 当我们向下和向右移动时，x和y值都会增加。(Python语言是零索引的，这意味着我们总是从零开始计数。)，看下图：</p><center><img src="https://i.imgur.com/CIsf7wW.png" alt=""></center><center>字母“I”放在一张图纸上.像素是通过他们的(x，y）坐标访问的，我们向右走x列，向下走y行(因为x是横坐标，y是纵坐标)，记住Python是零索引的：我们从零而不是一开始计数。</center><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><pre><code>from __future__ import print_functionimport argparseimport cv2 ap = argparse.ArgumentParser()ap.add_argument(&apos;-i&apos;,&quot;--image&quot;,required=True,        help=&quot;Path to the image&quot;)args = vars(ap.parse_args())image = cv2.imread(args[&quot;image&quot;])cv2.imshow(&quot;Original&quot;,image)</code></pre><p>请记住，OpenCV将图像表示为NumPy数组。概念上，我们可以将此表示视为一个矩阵。为了访问像素值，我们只需要提供我们感兴趣的像素的x和y坐标。但是，重要的是要注意<strong>OpenCV以相反的顺序存储RGB channels。 虽然我们通常用Red，Green和Blue(RGB)来思考，但OpenCV实际上按Blue，Green和Red的顺序存储它们(BGR)。</strong>如下面的代码：</p><pre><code>(b,g,r) = image[0,0]print(&quot;Pixel at (0,0) - Red:{}, Green： {}， Blue: {}&quot;.format(    r,g,b))image[0,0] = (0,0,255)(b,g,r) = image[0,0]print(&quot;Pixel at (0,0) - Red: {} , Green: {}, Blue: {}&quot;.format(r,    g,b))</code></pre><p><strong>解释</strong>：</p><p>我们首先抓取图像的左上角的像素，即(0,0)的位置。 这个像素表示为元组.同时，OpenCV以相反的顺序存储RGB像素，因此当我们解包并访问元组中的每个元素时，我们实际上是以BGR顺序查看它们。然后我们将像素RGB颜色打印出来。</p><p>接下来，我们操纵图像中的左上角像素，该像素位于坐标（0,0）处，并将其设置为(0,0,255)。 如果我们以RGB格式读取这个像素值，我们的红色值为0，绿色值为0，蓝色值为255，因此使其成为纯蓝色。但是，正如我上面提到的，在使用OpenCV时我们需要特别注意。 我们的像素实际上以BGR格式存储，而不是RGB格式。我们实际上将这个像素读为255为红色，0为绿色，0为蓝色，使其成为红色，而不是蓝色。</p><pre><code>corner = image[0:100,0:100]cv2.imshow(&quot;Corner&quot;,corner)image[0:100,0:100] = (0,255,0)cv2.imshow(&quot;Updated&quot;,image)cv2.waitKey(0)</code></pre><p><strong>解释</strong>：</p><p>接下来我们使用NumPy的数组切片功能来访问图像的较大矩形部分。为了访问图像较大的部分，Numpy希望我们提供四个索引值，分别是Start y,End y,Start x以及End x。 </p><p>最后，运行程序即可。</p><p><img src="https://i.imgur.com/cdnBl5U.png" alt=""></p><p>效果图：</p><p><img src="https://i.imgur.com/61ClxZk.png" alt=""></p><p>点击图片部分，按键盘任意键结束脚本。</p><p><strong>完整的代码</strong></p><pre><code>from __future__ import print_functionimport argparseimport cv2 ap = argparse.ArgumentParser()ap.add_argument(&apos;-i&apos;,&quot;--image&quot;,required=True,        help=&quot;Path to the image&quot;)args = vars(ap.parse_args())image = cv2.imread(args[&quot;image&quot;])cv2.imshow(&quot;Original&quot;,image)(b,g,r) = image[0,0]print(&quot;Pixel at (0,0) - Red:{}, Green： {}， Blue: {}&quot;.format(    r,g,b))image[0,0] = (0,0,255)(b,g,r) = image[0,0]print(&quot;Pixel at (0,0) - Red: {} , Green: {}, Blue: {}&quot;.format(r,    g,b))corner = image[0:100,0:100]cv2.imshow(&quot;Corner&quot;,corner)image[0:100,0:100] = (0,255,0)cv2.imshow(&quot;Updated&quot;,image)cv2.waitKey(0)</code></pre><p><strong>用到的函数</strong></p><p><span id="inline-blue">imread</span></p><p><span id="inline-blue">imshow</span></p><p><span id="inline-blue">waitKey</span></p><h3 id="更多的参考："><a href="#更多的参考：" class="headerlink" title="更多的参考："></a>更多的参考：</h3><p><a href="https://ppao.pyimagesearch.com/lessons/ppao-chapter-4-image-basics/" target="_blank" rel="noopener">chapter-4-image-basics</a></p><p><a href="https://www.learnopencv.com/why-does-opencv-use-bgr-color-format/" target="_blank" rel="noopener">why-does-opencv-use-bgr-color-format</a></p><p>总结起来就是：</p><p>有一些技术原因，但总的来说，为什么开发人员选择BGR格式的原因是因为在BGR中指定颜色值而不是RGB在当时更受欢迎 - 这就是全部。</p><hr>]]></content>
    
    <summary type="html">
    
      第二个代码
    
    </summary>
    
      <category term="计算机视觉" scheme="https://0Leo0.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="Oepncv" scheme="https://0Leo0.github.io/tags/Oepncv/"/>
    
  </entry>
  
  <entry>
    <title>OpenCV_python3_01</title>
    <link href="https://0Leo0.github.io//2018/OpenCV_python3_01.html"/>
    <id>https://0Leo0.github.io//2018/OpenCV_python3_01.html</id>
    <published>2018-11-08T11:17:57.000Z</published>
    <updated>2018-11-09T03:41:18.502Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><a id="more"></a><h2 id="Practical-Python-and-OpenCV-3rd-Edition-01"><a href="#Practical-Python-and-OpenCV-3rd-Edition-01" class="headerlink" title="Practical Python and OpenCV,3rd Edition 01"></a>Practical Python and OpenCV,3rd Edition 01</h2><hr><h3 id="load、display、save"><a href="#load、display、save" class="headerlink" title="load、display、save"></a>load、display、save</h3><pre><code>from __future__ import print_functionimport argparseimport cv2 </code></pre><p><strong>解释</strong>：</p><p>  从<strong>future</strong> package中导入print_function，是因为我们将使用实际的print() function，而不是print statement，这样我们的代码就可以在python2.7以及python3中共同运行。</p><pre><code>ap = argparse.ArgumentParser()ap.add_argument(&apos;-i&apos;,&quot;--image&quot;,required=True,    help=&quot;Path to the image&quot;)args = vars(ap.parse_args())</code></pre><p><strong>解释</strong>：</p><p>  使用“–image”参数，也就是我们图像在磁盘的路径，我们将这个路径进行parse，然后将他们存储在一个字典中。</p><pre><code>image = cv2.imread(args[&quot;image&quot;])print(&quot;height: {} pixels&quot;.format(image.shape[0]))print(&quot;width : {} pixels&quot;.format(image.shape[1]))print(&quot;channels : {}&quot;.format(image.shape[2]))cv2.imshow(&quot;Image&quot;,image)cv2.waitKey(0)</code></pre><p><strong>解释</strong>：</p><p>  cv2.imread函数将返回一个Numpy数据，代表着图像。对于Numpy数组，我们可以使用shape属性来获取图像的width、height以及channels的数量。imshow函数将我们的图像显示在Windows窗口中，它的第一个参数是”name” of our window.第二个参数是我们从磁盘加载的图像了。而waitKey函数会暂停我们的脚本程序，直到我们在键盘上按下一个key之后才继续执行，而参数0则表示我们按键盘上的任意键都可以继续执行脚本程序。</p><pre><code>cv2.imwrite(&quot;newimage.jpg&quot;,image)</code></pre><p><strong>解释</strong>：</p><p>  最后我们使用imwrite函数将我们的保存为jpg格式的图像，第一个参数是我们要保存的图像的路径名，第二个是我们希望保存的图像。</p><p>最后执行脚本程序：</p><p><img src="https://i.imgur.com/wUmgT2H.png" alt=""></p><p>显示效果图片</p><p><img src="https://i.imgur.com/JO02dxm.png" alt=""></p><p>停止脚本程序很简单，就如前面所说的，在显示的图片的任意地方按键盘上的任意键即可。然后查看脚本目录，你可以看到一个newimage.jpg的图片</p><p><img src="https://i.imgur.com/whM20GA.png" alt=""></p><p><strong>完整的代码</strong></p><pre><code>from __future__ import print_functionimport argparseimport cv2 ap = argparse.ArgumentParser()ap.add_argument(&apos;-i&apos;,&quot;--image&quot;,required=True,    help=&quot;Path to the image&quot;)args = vars(ap.parse_args())image = cv2.imread(args[&quot;image&quot;])print(&quot;height: {} pixels&quot;.format(image.shape[0]))print(&quot;width : {} pixels&quot;.format(image.shape[1]))print(&quot;channels : {}&quot;.format(image.shape[2]))cv2.imshow(&quot;Image&quot;,image)cv2.waitKey(0)cv2.imwrite(&quot;newimage.jpg&quot;,image)</code></pre><p><strong>用到的函数</strong></p><p><span id="inline-blue">imread</span></p><p><span id="inline-blue">imshow</span></p><p><span id="inline-blue">waitKey</span></p><p><span id="inline-blue">imwrite</span></p><div class="note danger no-icon"><p>danger no-icon</p></div><p>在上面的代码中，height对应于shape[0]，width对应于shape[1]。也就是Numpy 的shape似乎和自己想的不一样(specifying the height before the width)。但是，就matrix definition而言，这实际上是有意义。因为当我们定义矩阵的时候，我们通常将它们写成(# of rows x # of columns)的形式。这里，我们的图片有height：400 pixels(the number of rows) 以及 width：400 pixels(the number of columns).</p><h3 id="更多的参考："><a href="#更多的参考：" class="headerlink" title="更多的参考："></a>更多的参考：</h3><p><a href="https://ppao.pyimagesearch.com/lessons/ppao-chapter-3-loading-displaying-and-saving/" target="_blank" rel="noopener">loading-displaying-and-saving</a></p><p><a href="https://www.pyimagesearch.com/2014/06/02/opencv-load-image/" target="_blank" rel="noopener">How-To: OpenCV Load an Image</a></p><p><a href="https://www.cyberciti.biz/faq/python-command-line-arguments-argv-example/" target="_blank" rel="noopener">Python Command Line Arguments</a></p><p><a href="https://www.pyimagesearch.com/2014/11/03/display-matplotlib-rgb-image/" target="_blank" rel="noopener">How to Display a Matplotlib RGB Image</a></p><p><a href="https://www.pyimagesearch.com/2015/08/24/resolved-matplotlib-figures-not-showing-up-or-displaying/" target="_blank" rel="noopener">Resolved: Matplotlib figures not showing up or displaying</a></p><hr>]]></content>
    
    <summary type="html">
    
      第一个代码
    
    </summary>
    
      <category term="计算机视觉" scheme="https://0Leo0.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
    
      <category term="OpenCV" scheme="https://0Leo0.github.io/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>git学习之路_2_文件管理</title>
    <link href="https://0Leo0.github.io//2018/git_2.html"/>
    <id>https://0Leo0.github.io//2018/git_2.html</id>
    <published>2018-10-29T04:17:57.000Z</published>
    <updated>2018-11-04T12:26:15.830Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><a id="more"></a><h2 id="时光穿梭"><a href="#时光穿梭" class="headerlink" title="时光穿梭"></a>时光穿梭</h2><p>前面我们已经添加并提交了一个readme.txt文件，现在我们将文件进行修改，改为下面的内容：</p><p><img src="https://s1.ax1x.com/2018/11/04/i5oLX8.png" alt="修改readme.txt"></p><p>现在，我们运行命令<code>git status</code>看一看会有什么结果：</p><p><img src="https://s1.ax1x.com/2018/11/04/i5oTfI.png" alt="运行git status命令"></p><p><code>git status</code>命令可以让我们时刻掌握仓库当前的状态，从上图中可以看出来，redme.txt文件显然被修改过了，但是我们并没有准备提交我们的修改。如果我们不知道修改了什么样的内容，我们可以运行命令<code>git diff</code>来查看具体修改了什么样的内容。</p><p><img src="https://s1.ax1x.com/2018/11/04/i5oHpt.png" alt="运行git diff命令"></p><p>diff是英文difference的缩写，上图中显示的格式是Unix通用的diff格式，知道了我们对readme.txt文件做了那些修改，接下来我们把文件提交到仓库中，一样是两个步骤，第一步运行命令<code>git add</code></p><pre><code>git add readme.txt </code></pre><p>接下来在执行<code>git commit</code>命令之前，我们用命令<code>git status</code>看看当前仓库的状态</p><p><img src="https://s1.ax1x.com/2018/11/04/i5ootA.png" alt="运行git status命令"></p><p>上面的<code>git status</code>命令告诉我们，将要被提交的修改包括readme.txt，接下来，我们可以放心的提交了：</p><p><img src="https://s1.ax1x.com/2018/11/04/i5oq6f.png" alt="运行git commit命令"></p><p>进行了提交之后，我们再用<code>git status</code>命令来查看仓库的当前状态</p><p><img src="https://s1.ax1x.com/2018/11/04/i5ob1P.png" alt="运行git commit命令"></p><p>Git告诉我们当前没有需要提交的修改，而且，工作目录是干净的(working tree clean)</p><p><span id="inline-blue">本节命令</span></p><p><code>git status</code>：掌握工作区的状态</p><p>‘<code>git diff</code>：查看修改的内容</p><h2 id="参考来源"><a href="#参考来源" class="headerlink" title="参考来源"></a>参考来源</h2><p><a href="https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/0013743858312764dca7ad6d0754f76aa562e3789478044000" target="_blank" rel="noopener">Git 时光穿梭 </a></p><p><a href="https://www.git-tower.com/blog/git-cheat-sheet/" target="_blank" rel="noopener">Git cheat sheet英文版</a></p><p><a href="https://www.kancloud.cn/thinkphp/git-cheat-sheet/39651" target="_blank" rel="noopener">Git cheat sheet中文版</a></p><hr>]]></content>
    
    <summary type="html">
    
      git学习之时光穿梭
    
    </summary>
    
      <category term="git" scheme="https://0Leo0.github.io/categories/git/"/>
    
    
      <category term="git" scheme="https://0Leo0.github.io/tags/git/"/>
    
  </entry>
  
  <entry>
    <title>git学习之路_1_安装git以及创建版本库</title>
    <link href="https://0Leo0.github.io//2018/git_1.html"/>
    <id>https://0Leo0.github.io//2018/git_1.html</id>
    <published>2018-10-28T08:17:57.000Z</published>
    <updated>2018-10-29T04:11:00.393Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><a id="more"></a><h2 id="windows上安装Git"><a href="#windows上安装Git" class="headerlink" title="windows上安装Git"></a>windows上安装Git</h2><p>下载git for windows，新手默认安装即可。</p><p>官方网址为：<a href="https://gitforwindows.org/" target="_blank" rel="noopener">https://gitforwindows.org/</a></p><p>安装完成之后，下一步就应该告诉git你来自哪里。因为Git是分布式版本控制系统，所以每个机器必须自报家门，即告诉git，你的名字和Email地址，命令为：</p><pre><code>git config --global user.name &quot;your name&quot;git config --global user.email &quot;your email&quot;</code></pre><p>注意：(引号内请输入你自己设置的名字和自己的邮箱),此用户名和邮箱是git提交代码时用来显示你的身份和联系方式的，并不是github用户名和邮箱。其中<code>--global</code>参数表示你这台及其上所有的git仓库都会使用这个配置。</p><h2 id="创建版本库"><a href="#创建版本库" class="headerlink" title="创建版本库"></a>创建版本库</h2><p>首先这里再明确一下，所有的版本控制系统，其实只能跟踪文本文件的改动，比如TXT文件，网页，所有的程序代码等等，Git也不例外。版本控制系统可以告诉你每次的改动，比如在第5行加了一个单词“Linux”，在第8行删了一个单词“Windows”。而图片、视频这些二进制文件，虽然也能由版本控制系统管理，但没法跟踪文件的变化，只能把二进制文件每次改动串起来，也就是只知道图片从100KB改成了120KB，但到底改了啥，版本控制系统不知道，也没法知道。</p><p>在Windows系统上，为了避免各种莫名其妙的问题，请确保目录名(不管是子目录还是父目录)不要包含中文。</p><p>之后使用命令<code>git init</code>来将这个目录变成Git可以管理的仓库。<br><img src="https://s1.ax1x.com/2018/10/28/icvY1f.png" alt="初始化仓库"></p><p>Git仓库建好了，还是一个空的仓库，同时在该目录下会有一个隐藏的<code>.git</code>目录，这个目录是用来跟踪管理版本库的，没事千万别修改哦！</p><ul><li>把文件添加到版本库中</li></ul><p>首先是文本编辑器的编码问题，强烈推荐使用UTF-8编码，而在Windows上不用使用Windows自带的<strong>记事本</strong>，可以选择notepad++，将默认编码改为：UTF-8 without BOM即可<br><img src="https://s1.ax1x.com/2018/10/28/icvBAs.png" alt="编码"></p><p>让我们来新建一个readme.txt文件，输入下面的内容，<br><img src="https://s1.ax1x.com/2018/10/28/icvw7j.png" alt="readme.txt"></p><p><strong>注意</strong>：这个文件一定要放在init的目录(或者子目录也行)下(否则git不能管理)，接着，把这个文件放到git仓库中只需要两步即可。</p><ol><li><p>用<code>git add</code>告诉Git，把该文件添加到仓库中 </p><p> git add readme.txt </p></li><li><p>用<code>git commit</code>告诉Git，把文件提交到仓库中 </p><p> git commit -m “wrote a readme file”</p></li></ol><p>上述命令的<code>-m</code>表示本次提交的说明(comment),可以输入任何内容，有意义最好，这样你就可以从历史记录里面方便地找到改动的记录。<br><img src="https://s1.ax1x.com/2018/10/28/icvdBQ.png" alt="提交"></p><p>在执行完<code>git commit</code>命令之后，就会告诉你，<font color="red">1 file changed</font>:1个文件被改动(我们添加了readme.txt)；<font color="red">2 insertions</font>：插入了两行内容(readme.txt有两行内容)</p><p><span id="inline-blue">小贴士</span></p><p>为什么Git添加问价需要先add，再commit呢？因为commit命令可以一次提交很多文件(将add进去的文件都提交上去)，所以你可以多次add不同的文件。</p><p>比如：</p><pre><code>git add file1.txt file2.txtgit commit -m &quot;add 2 files&quot;</code></pre><h2 id="参考来源"><a href="#参考来源" class="headerlink" title="参考来源"></a>参考来源</h2><p><a href="https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/001373962845513aefd77a99f4145f0a2c7a7ca057e7570000" target="_blank" rel="noopener">Git 简介</a></p><p><a href="https://www.git-tower.com/blog/git-cheat-sheet/" target="_blank" rel="noopener">Git cheat sheet英文版</a></p><p><a href="https://www.kancloud.cn/thinkphp/git-cheat-sheet/39651" target="_blank" rel="noopener">Git cheat sheet中文版</a></p><hr>]]></content>
    
    <summary type="html">
    
      开启git学习之路
    
    </summary>
    
      <category term="git" scheme="https://0Leo0.github.io/categories/git/"/>
    
    
      <category term="git" scheme="https://0Leo0.github.io/tags/git/"/>
    
  </entry>
  
  <entry>
    <title>markdown语法学习</title>
    <link href="https://0Leo0.github.io//2018/Markdown%20grammar.html"/>
    <id>https://0Leo0.github.io//2018/Markdown grammar.html</id>
    <published>2018-10-26T11:17:57.000Z</published>
    <updated>2018-10-27T17:04:22.290Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p class="description"></p><a id="more"></a><h2 id="欢迎使用MarkdownPad编辑阅读器"><a href="#欢迎使用MarkdownPad编辑阅读器" class="headerlink" title="欢迎使用MarkdownPad编辑阅读器"></a>欢迎使用MarkdownPad编辑阅读器</h2><hr><h3 id="粗体和斜体"><a href="#粗体和斜体" class="headerlink" title="粗体和斜体"></a>粗体和斜体</h3><p>使用 一对<code>*</code> 或者 <code>_</code> 表示包围的字体斜体显示<br>而一对<code>**</code> 或者<code>__</code> 来表示粗体。</p><p>例如：</p><pre><code>*你好，世界***你好，世界**</code></pre><p>显示效果为：</p><p><em>你好，世界</em></p><p><strong>你好，世界</strong></p><h3 id="分级标题"><a href="#分级标题" class="headerlink" title="分级标题"></a>分级标题</h3><p>Markdown 的标题有Setext和Atx两种语法形式，在Setex中，在文本下面标注<code>=</code>表示最高级标题，在下面标注<code>-</code>表示第二级标题，比如下面的Setext形式输出一级标题和二级标题</p><pre><code>Headline 1==========Headline 2--</code></pre><p>当然也可以使用Atx形式输出各级标题</p><pre><code>#Headline 1 ##Headline 2</code></pre><h3 id="段落"><a href="#段落" class="headerlink" title="段落"></a>段落</h3><p>Markdown中使用空白行来分割段落，比如下面两端文本，只需要在两端之间加上一行空行，Markdown就会为文本分段</p><pre><code>Hello world 我是空白行  你好啊世界</code></pre><p>显示效果为：</p><p>Hello world </p><p>你好啊世界</p><h3 id="字体"><a href="#字体" class="headerlink" title="字体"></a>字体</h3><p>Markdown支持HTML嵌套，我们可以利用HTML标记实现更改颜色的需求，更改颜色代码如下：</p><pre><code>Default Color&lt;font color=&apos;red&apos;&gt;Red Color&lt;/font&gt;&lt;font color=&apos;blue&apos;&gt;Blue Color&lt;/font&gt;&lt;font color=&apos;green&apos;&gt;Green Color&lt;/font&gt;&lt;font color=&apos;yellow&apos;&gt;Yellow Color&lt;/font&gt;&lt;font color=&apos;pink&apos;&gt;Pink Color&lt;/font&gt;&lt;font color=&apos;purple&apos;&gt;Purple Color&lt;/font&gt;&lt;font color=&apos;orange&apos;&gt;Orange Color&lt;/font&gt;</code></pre><p>显示效果为：</p><font color="red">Red Color</font><font color="blue">Blue Color</font><font color="green">Green Color</font><font color="yellow">Yellow Color</font><font color="pink">Pink Color</font><font color="purple">Purple Color</font><font color="orange">Orange Color</font><p>更改字号、字体也可以使用HTML轻松实现</p><pre><code>&lt;font size=&apos;-2&apos;&gt;Small Size&lt;/font&gt;Normal Size&lt;font size=&apos;+2&apos;&gt;Big Size&lt;/font&gt;&lt;font size=&apos;+2&apos; face=&apos;楷体&apos;&gt;楷体&lt;/font&gt;</code></pre><p>输出显示为：</p><font size="-2">Small Size</font><p>Normal Size</p><font size="+2">Big Size</font><font size="+2" face="楷体">楷体</font><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><p>Markdown使用email的区块引用方式，即右尖括号<code>&gt;</code>后面跟引用的内容，如下</p><pre><code>&gt;Hello World&gt;你好，世界</code></pre><p>其输出为：</p><blockquote><p>Hello World </p></blockquote><blockquote><p>你好，世界</p></blockquote><h3 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h3><p>Markdown中使用型号<code>*</code> , 加号<code>+</code> 以及减号<code>-</code> 来表示无序列表(中间有空格)</p><pre><code>* 我是列表+ 我也是列表- 我还是列表</code></pre><p>其输出为：</p><ul><li>我是列表</li></ul><ul><li>我也是列表</li></ul><ul><li>我还是列表</li></ul><p>有序列表使用一个数字加一个英文句点作为项目标记，比如</p><pre><code>1. 我是列表2. 我也是列表</code></pre><p>其输出如下：</p><ol><li><p>我是列表</p></li><li><p>我也是列表</p></li></ol><p>同时，列表也是可以进行嵌套使用的(中间不用空格)，比如：</p><pre><code>1.你好，世界&gt;你好，世界2.Hello World&gt;Hello World</code></pre><p>输出结果为：</p><p>1.你好，世界</p><blockquote><p>你好，世界</p></blockquote><p>2.Hello World</p><blockquote><p>Hello World</p></blockquote><h3 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h3><p>Markdown支持行内和参考两种形式的链接语法，两种都是使用中括号来把文字转成链接，行内形式是中括号包围文字，后面紧跟圆括号包围的链接，其代码如下所示：</p><pre><code>[我的博客](https://0leo0.github.io/)</code></pre><p>其输出为：</p><p><a href="https://0leo0.github.io/">我的博客</a></p><p>当然，我们也可以给我们的链接加上一个title属性，</p><pre><code>[我的博客](https://0leo0.github.io/ &quot;我是一个标题&quot;)</code></pre><p>输出如下：</p><p><a href="https://0leo0.github.io/" title="我是一个标题">我的博客</a></p><p>参考形式的链接可以在原文中为链接定义一个名称，然后在文章的其他地方定义该链接的内容，其语法格式为 <code>[链接文本][链接名称]</code> </p><pre><code>我想搜索关于Python的内容，可以去[Google][1],以及[Yahoo][2]和[Baidu][3]</code></pre><p>然后在别的地方定义链接内容，语法格式为<code>[链接名称]:空白符 URL &quot;title&quot;</code></p><pre><code>[1]: https://google.com/ &quot;Google&quot;[2]: https://yahoo.com/ &quot;Yahoo&quot;[3]: https://baidu.com/ &quot;Baidu&quot;</code></pre><p>显示效果为：</p><p>我想搜索关于Python的内容，可以去<a href="https://google.com/" title="Google" target="_blank" rel="noopener">Google</a>,以及<a href="https://yahoo.com/" title="Yahoo" target="_blank" rel="noopener">Yahoo</a>和<a href="https://baidu.com/" title="Baidu" target="_blank" rel="noopener">Baidu</a></p><p>另外，使用<code>&lt;&gt;</code> 包括的URL或者邮箱地址会被自动转换为超链接</p><pre><code>&lt;https://0leo0.github.io/&gt;&lt;wen_9407@yahoo.com&gt;</code></pre><p>效果如下：</p><p><a href="https://0leo0.github.io/">https://0leo0.github.io/</a></p><p><a href="mailto:&#x77;&#x65;&#110;&#x5f;&#x39;&#52;&#48;&#55;&#x40;&#121;&#x61;&#x68;&#111;&#111;&#46;&#x63;&#111;&#x6d;" target="_blank" rel="noopener">&#x77;&#x65;&#110;&#x5f;&#x39;&#52;&#48;&#55;&#x40;&#121;&#x61;&#x68;&#111;&#111;&#46;&#x63;&#111;&#x6d;</a></p><h3 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h3><p>图片的语法格式和链接类似，也分为行内形式和参考形式。</p><p>行内形式语法格式为：<code>![alt text](URL title)</code>,其中alt,text以及text都可以选择性的加入，但URL必须有</p><pre><code>![我要显示图片](https://imgchr.com/i/iy5Th9)</code></pre><p>显示的效果如下：</p><p><img src="https://s1.ax1x.com/2018/10/26/iy5Th9.jpg" alt="我要显示图片" title="海贼王"></p><p>参考形式分为两部分，声明图片链接名称和定义图片链接</p><p>其中声明图片链接语法格式为：<code>![alt text][id]</code></p><p>定义图片链接内容的语法格式为： <code>[id]:URL &quot;title&quot;</code>.</p><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><p>在一般段落文字中，可以使用反引号`来标记代码区段。</p><pre><code>我喜欢这个世界`&lt;blank&gt;`，哈哈</code></pre><p>显示效果</p><p>我喜欢这个世界<code>&lt;blank&gt;</code>，哈哈</p><p>在Markdown中，如果行开头有4个空格，将被视为代码。但是这种方式，不推荐，我们推荐的方式是代码块的首行用3个反引号`和编程语言名称(C、Python等)标记代码块开始，代码块的结尾用3个反引号来闭合代码块。</p><p>比如，将一段python代码插入到Markdown，首行用3个反引号来标记代码块，最后一行再用3个反引号来闭合代码块。</p><pre><code><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">"calculate X to the power of Y"</span>)</span><br><span class="line">parser.add_argument(<span class="string">'square'</span>,type=int,\</span><br><span class="line">        help=<span class="string">"display a square of a given number"</span>)</span><br><span class="line">parser.add_argument(<span class="string">'-v'</span>,<span class="string">"--verbosity"</span>,type=int,choices=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],\</span><br><span class="line">        default=<span class="number">1</span>,help=<span class="string">"increase output verbosity"</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line">answer = args.square ** <span class="number">2</span></span><br></pre></td></tr></table></figure></code></pre><p>那么其显示效果为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">"calculate X to the power of Y"</span>)</span><br><span class="line"></span><br><span class="line">parser.add_argument(<span class="string">'square'</span>,type=int,\</span><br><span class="line">        help=<span class="string">"display a square of a given number"</span>)</span><br><span class="line"></span><br><span class="line">parser.add_argument(<span class="string">'-v'</span>,<span class="string">"--verbosity"</span>,type=int,choices=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],\</span><br><span class="line">        default=<span class="number">1</span>,help=<span class="string">"increase output verbosity"</span>)</span><br><span class="line"></span><br><span class="line">args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">answer = args.square ** <span class="number">2</span></span><br></pre></td></tr></table></figure><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p>考虑HTML和CSS<br>(使用列表的话，下面的会显示出作用，而不是以代码的形式显示出来)</p><p>1.分割线和空行</p><pre><code>/*分割线*/&lt;hr /&gt;/*空行*/&lt;br /&gt;</code></pre><p>2.引用</p><pre><code>&lt;blockquote&gt;引用内容&lt;/blockquote&gt;/*如果上下间距很小，可以加个P*/&lt;p&gt;&lt;blockquote&gt;引用内容&lt;/blockquote&gt;&lt;/p&gt;</code></pre><p>3.居中与右对齐</p><pre><code>/*居中*/&lt;center&gt;内容&lt;/center&gt;/*右对齐*/&lt;p style=&quot;text-align:right&quot;&gt;内容&lt;/p&gt;</code></pre><p>4.字体大小和颜色</p><pre><code>&lt;font colr=&quot;#xxxxxx&quot; size=&quot;numbr&quot;&gt;内容&lt;/font&gt;//详细请查看W3schcool：https://www.w3school.com.cn/tags/tag_font.asp</code></pre><p>5.Todo list</p><pre><code>&lt;ul&gt;&lt;li&gt;&lt;i class=&quot;fa fa-check-square&quot;&gt;&lt;/i&gt;已完成&lt;/li&gt;&lt;li&gt;&lt;i class=&quot;fa fasquare&quot;&gt;&lt;/i&gt;未完成&lt;/li&gt;&lt;/ul&gt;</code></pre><h2 id="Markdown-高阶语法"><a href="#Markdown-高阶语法" class="headerlink" title="Markdown 高阶语法"></a>Markdown 高阶语法</h2><h3 id="内容目录"><a href="#内容目录" class="headerlink" title="内容目录"></a>内容目录</h3><p>在段落中填写[TOC]以显示全文内容的目录结构</p><p>[TOC]</p><h3 id="标签分类"><a href="#标签分类" class="headerlink" title="标签分类"></a>标签分类</h3><p>在编辑区任意行的的列首位置输入以下代码给文稿标签： </p><p>标签: 数学 英语 Markdown</p><p>或者</p><p>Tags: 数学 英语 Markdown</p><h3 id="删除线"><a href="#删除线" class="headerlink" title="删除线"></a>删除线</h3><p>使用~~ 表示删除线。</p><p>~~ 这是一段错误的文本 ~~</p><h3 id="脚注"><a href="#脚注" class="headerlink" title="脚注"></a>脚注</h3><p>使用[^keyword]表示脚注</p><p>这是一个脚注<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>的样例</p><h3 id="LaTex公式"><a href="#LaTex公式" class="headerlink" title="LaTex公式"></a>LaTex公式</h3><p>$表示行内公式</p><p>质能守恒方程 $E=mc<sup>2</sup></p><p>这里的上标我使用sup / sup，用四个尖括号括起来，同样下标为sub</p><p>而$$表示整行公式，具体参考<a href="https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference" target="_blank" rel="noopener">MathJax</a></p><hr><h3 id="参考网址："><a href="#参考网址：" class="headerlink" title="参考网址："></a>参考网址：</h3><p><a href="https://www.zybuluo.com/static/editor/cmd-manual.html" target="_blank" rel="noopener">Cmd Markdown简明语法手册</a></p><p><a href="https://www.cnblogs.com/dezheng/p/3834813.html" target="_blank" rel="noopener">Markdown入门基础</a></p><p><a href="https://fontawesome.com/v4.7.0/examples/" target="_blank" rel="noopener">fontawesome</a></p><p><a href="https://reuixiy.github.io/technology/computer/computer-aided-art/2017/06/09/hexo-next-optimization.html" target="_blank" rel="noopener">reuixiy</a></p><p><span id="inline-blue">后话</span></p><p>第一篇markdown写的文章弄的我好辛苦，主要是用markdownpad编辑好的和hexo解析出的html不一样，在网页上看到的不是自己想要的，后面希望会好一点吧！！</p><hr>]]></content>
    
    <summary type="html">
    
      什么？你竟然还不会用markdown？
    
    </summary>
    
      <category term="markdown" scheme="https://0Leo0.github.io/categories/markdown/"/>
    
    
      <category term="markdown" scheme="https://0Leo0.github.io/tags/markdown/"/>
    
  </entry>
  
</feed>
